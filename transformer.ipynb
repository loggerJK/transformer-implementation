{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1meTcsQISzrq"
      },
      "source": [
        "# Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JkFt8wlvSzrv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50caf6bd-31d2-42ce-89a9-a30c33f15c9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 57 kB 2.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 10.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 37.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 96 kB 5.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 58.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 180 kB 53.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 97 kB 7.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "! pip install Korpora sentencepiece einops wandb -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WxM006iV5StT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from Korpora import Korpora\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "# from konlpy.tag import Mecab\n",
        "from nltk.tokenize import word_tokenize as en_tokenizer\n",
        "import sentencepiece as spm\n",
        "import urllib.request\n",
        "import csv\n",
        "import numpy as np\n",
        "from einops import rearrange, reduce, repeat\n",
        "from torch.cuda import amp\n",
        "from tqdm import tqdm\n",
        "import wandb\n",
        "import time\n",
        "import copy\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuuFjEE8Szry",
        "outputId": "a560241e-d93c-4cfd-ee9a-d365562d60af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda\n"
          ]
        }
      ],
      "source": [
        "VOCAB_SIZE = 32000 + 7\n",
        "SEQ_LEN = 200\n",
        "PAD_IDX = 0\n",
        "TRAIN_LEN = 100000\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "KWd0k3I0RBD2",
        "outputId": "cc3dde5a-a23d-44dd-8e7d-5d399103c252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjiwon7258\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/jiwon7258/petfinder-pawpularity-score/runs/j3t70e30\" target=\"_blank\">brisk-sky-87</a></strong> to <a href=\"https://wandb.ai/jiwon7258/petfinder-pawpularity-score\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "# if want to run in offline mode\n",
        "\n",
        "# os.environ[\"WANDB_API_KEY\"] = \"d60a4af56f6cd9cccec7d9da1dbced7960b61310\"\n",
        "# os.environ[\"WANDB_MODE\"] = \"dryrun\"\n",
        "# wandb.init(project=\"petfinder-pawpularity-score\", entity=\"jiwon7258\")\n",
        "\n",
        "\n",
        "wandb.login(key=\"d60a4af56f6cd9cccec7d9da1dbced7960b61310\")\n",
        "wandb.init(project=\"petfinder-pawpularity-score\", entity=\"jiwon7258\")\n",
        "wandb.run.name = \"Transformer\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQrKlhKPSzrz"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZtd6ivuCz_z",
        "outputId": "f6ea3edb-7503-4051-d817-814e657f1016"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
            "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
            "\n",
            "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
            "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
            "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
            "\n",
            "    # Description\n",
            "    Author : TRAC (https://trac.edgewall.org/)\n",
            "    Repository : http://opus.nlpl.eu/OpenSubtitles-v2018.php\n",
            "    References :\n",
            "        - P. Lison and J. Tiedemann, 2016, OpenSubtitles2016: Extracting Large Parallel Corpora\n",
            "          from Movie and TV Subtitles. In Proceedings of the 10th International Conference on\n",
            "          Language Resources and Evaluation (LREC 2016)\n",
            "\n",
            "    This is a new collection of translated movie subtitles from http://www.opensubtitles.org/.\n",
            "\n",
            "    [[ IMPORTANT ]]\n",
            "    If you use the OpenSubtitle corpus: Please, add a link to http://www.opensubtitles.org/\n",
            "    to your website and to your reports and publications produced with the data!\n",
            "    I promised this when I got the data from the providers of that website!\n",
            "\n",
            "    This is a slightly cleaner version of the subtitle collection using improved sentence alignment\n",
            "    and better language checking.\n",
            "\n",
            "    62 languages, 1,782 bitexts\n",
            "    total number of files: 3,735,070\n",
            "    total number of tokens: 22.10G\n",
            "    total number of sentence fragments: 3.35G\n",
            "\n",
            "    [[ NOTICE ]]\n",
            "    In original data, the source language is `en` and target language is `ko`. However in Korpora,\n",
            "    we change the language pair so that source language is `ko` and target language is `en`.\n",
            "\n",
            "    # License\n",
            "    Open Data. Details in https://opendefinition.org/od/2.1/en/\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[open_subtitles] download en-ko.tmx.gz: 48.1MB [00:04, 11.2MB/s]                            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decompress /content/open_subtitles/en-ko.tmx.gz\n"
          ]
        }
      ],
      "source": [
        "# dataset = open_subtitles_dataset()\n",
        "corpus = Korpora.load(\"open_subtitles\", root_dir='./')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CpuQ8uGZOFqQ",
        "outputId": "7b28d4e1-2001-4f3d-e9c8-4c98d314b079"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-25c41fd5-8817-44b1-86c7-5638cacdf1b4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>trg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Through the snow and sleet and hail, through t...</td>\n",
              "      <td>폭설이 내리고 우박, 진눈깨비가 퍼부어도 눈보라가 몰아쳐도 강풍이 불고 비바람이 휘...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ever faithful, ever true, nothing stops him, h...</td>\n",
              "      <td>우리의 한결같은 심부름꾼 황새 아저씨 가는 길을 그 누가 막으랴!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Look out for Mr Stork That persevering chap</td>\n",
              "      <td>황새 아저씨를 기다리세요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>He'll come along and drop a bundle in your lap</td>\n",
              "      <td>찾아와 선물을 주실 거예요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You may be poor or rich It doesn't matter which</td>\n",
              "      <td>가난하든 부자이든 상관이 없답니다</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25c41fd5-8817-44b1-86c7-5638cacdf1b4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-25c41fd5-8817-44b1-86c7-5638cacdf1b4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-25c41fd5-8817-44b1-86c7-5638cacdf1b4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 src                                                trg\n",
              "0  Through the snow and sleet and hail, through t...  폭설이 내리고 우박, 진눈깨비가 퍼부어도 눈보라가 몰아쳐도 강풍이 불고 비바람이 휘...\n",
              "1  ever faithful, ever true, nothing stops him, h...               우리의 한결같은 심부름꾼 황새 아저씨 가는 길을 그 누가 막으랴!\n",
              "2        Look out for Mr Stork That persevering chap                                      황새 아저씨를 기다리세요\n",
              "3     He'll come along and drop a bundle in your lap                                     찾아와 선물을 주실 거예요\n",
              "4    You may be poor or rich It doesn't matter which                                 가난하든 부자이든 상관이 없답니다"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data = pd.DataFrame([corpus.train.pairs, corpus.train.texts], index = ['src', 'trg'])\n",
        "data = data.transpose()\n",
        "data.to_csv('data.txt', index=False)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GhEK8vW5Szr1",
        "outputId": "a979dbc3-f93a-4d96-be06-06cdb13ef128"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-996112b3-8697-4856-94d9-18ffc5fc5e88\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>trg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Through the snow and sleet and hail, through t...</td>\n",
              "      <td>폭설이 내리고 우박, 진눈깨비가 퍼부어도 눈보라가 몰아쳐도 강풍이 불고 비바람이 휘...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ever faithful, ever true, nothing stops him, h...</td>\n",
              "      <td>우리의 한결같은 심부름꾼 황새 아저씨 가는 길을 그 누가 막으랴!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Look out for Mr Stork That persevering chap</td>\n",
              "      <td>황새 아저씨를 기다리세요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>He'll come along and drop a bundle in your lap</td>\n",
              "      <td>찾아와 선물을 주실 거예요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You may be poor or rich It doesn't matter which</td>\n",
              "      <td>가난하든 부자이든 상관이 없답니다</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-996112b3-8697-4856-94d9-18ffc5fc5e88')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-996112b3-8697-4856-94d9-18ffc5fc5e88 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-996112b3-8697-4856-94d9-18ffc5fc5e88');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 src                                                trg\n",
              "0  Through the snow and sleet and hail, through t...  폭설이 내리고 우박, 진눈깨비가 퍼부어도 눈보라가 몰아쳐도 강풍이 불고 비바람이 휘...\n",
              "1  ever faithful, ever true, nothing stops him, h...               우리의 한결같은 심부름꾼 황새 아저씨 가는 길을 그 누가 막으랴!\n",
              "2        Look out for Mr Stork That persevering chap                                      황새 아저씨를 기다리세요\n",
              "3     He'll come along and drop a bundle in your lap                                     찾아와 선물을 주실 거예요\n",
              "4    You may be poor or rich It doesn't matter which                                 가난하든 부자이든 상관이 없답니다"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data = pd.read_csv('data.txt')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYHmUVpWSzr2"
      },
      "source": [
        "## Sentencepiece Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qKGd7SI8OFqR"
      },
      "outputs": [],
      "source": [
        "with open('src.txt', mode = 'w', encoding='utf8') as f:\n",
        "    f.write('\\n'.join(data['src']))\n",
        "with open('trg.txt', mode= 'w', encoding='utf8') as f:\n",
        "    f.write('\\n'.join(data['trg']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7SHuXFE2Szr4"
      },
      "outputs": [],
      "source": [
        "# corpus = \"src.txt\"\n",
        "# prefix = \"src\"\n",
        "# vocab_size = 32000\n",
        "# spm.SentencePieceTrainer.train(\n",
        "#     f\"--input={corpus} --model_prefix={prefix} --vocab_size={vocab_size + 7}\" +\n",
        "#     \" --model_type=bpe\" +\n",
        "#     \" --max_sentence_length=999999\" +  # 문장 최대 길이\n",
        "#     \" --pad_id=0 --pad_piece=[PAD]\" +  # pad (0)\n",
        "#     \" --unk_id=1 --unk_piece=[UNK]\" +  # unknown (1)\n",
        "#     \" --bos_id=2 --bos_piece=[BOS]\" +  # begin of sequence (2)\n",
        "#     \" --eos_id=3 --eos_piece=[EOS]\" +  # end of sequence (3)\n",
        "#     \" --user_defined_symbols=[SEP],[CLS],[MASK]\")  # 사용자 정의 토큰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkWheMYvSzr5",
        "outputId": "395fafe7-c105-4143-f6fc-e8aec662814b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁I', '▁didn', \"'\", 't', '▁at', '▁all', '▁think', '▁of', '▁it', '▁this', '▁way', '.']\n",
            "[14, 346, 31954, 31935, 178, 163, 232, 64, 58, 115, 343, 31944]\n",
            "['▁I', '▁have', '▁waited', '▁a', '▁long', '▁time', '▁for', '▁someone', '▁to', '▁film']\n",
            "[14, 114, 5073, 10, 519, 280, 103, 731, 30, 3650]\n",
            "['▁[', 'P', 'AD', ']', '▁', '[CLS]', '▁[', 'B', 'OS', ']', '▁[', 'E', 'OS', ']', '▁', '[SEP]', '▁[', 'UN', 'K', ']']\n",
            "[361, 31980, 3429, 31992, 31933, 5, 361, 31974, 3377, 31992, 361, 31978, 3377, 31992, 31933, 4, 361, 2774, 31987, 31992]\n"
          ]
        }
      ],
      "source": [
        "sp_src = spm.SentencePieceProcessor()\n",
        "sp_src.Load('src.model')\n",
        "lines = [\n",
        "    \"I didn't at all think of it this way.\",\n",
        "    \"I have waited a long time for someone to film\",\n",
        "    \"[PAD] [CLS] [BOS] [EOS] [SEP] [UNK] \"\n",
        "]\n",
        "for line in lines:\n",
        "    print(sp_src.EncodeAsPieces(line))\n",
        "    print(sp_src.EncodeAsIds(line))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "n9O90jzgSzr6"
      },
      "outputs": [],
      "source": [
        "# corpus = \"trg.txt\"\n",
        "# prefix = \"trg\"\n",
        "# vocab_size = 32000\n",
        "# spm.SentencePieceTrainer.train(\n",
        "#     f\"--input={corpus} --model_prefix={prefix} --vocab_size={vocab_size + 7}\" +\n",
        "#     \" --model_type=bpe\" +\n",
        "#     \" --max_sentence_length=999999\" +  # 문장 최대 길이\n",
        "#     \" --pad_id=0 --pad_piece=[PAD]\" +  # pad (0)\n",
        "#     \" --unk_id=1 --unk_piece=[UNK]\" +  # unknown (1)\n",
        "#     \" --bos_id=2 --bos_piece=[BOS]\" +  # begin of sequence (2)\n",
        "#     \" --eos_id=3 --eos_piece=[EOS]\" +  # end of sequence (3)\n",
        "#     \" --user_defined_symbols=[SEP],[CLS],[MASK]\")  # 사용자 정의 토큰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1MLyIl0Szr7",
        "outputId": "6b7e0152-12ea-43a0-91aa-c6a369929952"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁알', '잘', '딱', '깔', '센', '▁임마', '▁그거', '▁몰라', '?', '.']\n",
            "[28, 30693, 31173, 31412, 31227, 5378, 635, 467, 30557, 30547]\n",
            "['▁하', '..', '▁존나', '▁싫다', '...']\n",
            "[14, 15, 5522, 9095, 27]\n",
            "['▁가족이', '▁사람을', '▁죽여서', '▁면', '목이', '▁없다', '거나', '▁같이', '▁살던', '▁사람들이', '▁살해당', '해서', '▁책임을', '▁느낀', '다거나', '▁자신의', '▁이런', '▁저런', '▁일로']\n",
            "[2957, 970, 17264, 1568, 8939, 1288, 792, 364, 12102, 671, 8318, 200, 7016, 8210, 23194, 2029, 275, 2758, 3525]\n",
            "['▁[', 'P', 'A', 'D', ']', '▁', '[CLS]', '▁[', 'B', 'O', 'S', ']', '▁[', 'EO', 'S', ']', '▁', '[SEP]', '▁[', 'UN', 'K', ']']\n",
            "[699, 31049, 30846, 30963, 31062, 30545, 5, 699, 30955, 30947, 30856, 31062, 699, 6999, 30856, 31062, 30545, 4, 699, 17323, 31214, 31062]\n"
          ]
        }
      ],
      "source": [
        "sp_trg = spm.SentencePieceProcessor()\n",
        "sp_trg.Load('trg.model')\n",
        "lines = [\n",
        "    \"알잘딱깔센 임마 그거 몰라?.\",\n",
        "    \"하.. 존나 싫다...\",\n",
        "    \"가족이 사람을 죽여서 면목이 없다거나 같이 살던 사람들이 살해당해서 책임을 느낀다거나 자신의 이런 저런 일로\",\n",
        "    \"[PAD] [CLS] [BOS] [EOS] [SEP] [UNK] \"\n",
        "]\n",
        "for line in lines:\n",
        "    print(sp_trg.EncodeAsPieces(line))\n",
        "    print(sp_trg.EncodeAsIds(line))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dceb4asCSzr7"
      },
      "source": [
        "## SRC Data (EN) Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "m4PVun3kSzr7"
      },
      "outputs": [],
      "source": [
        "def en_encode(tmpstr:str) -> np.array :\n",
        "    tmpstr = np.array(sp_src.EncodeAsIds(tmpstr))\n",
        "\n",
        "    # SEQ_LEN보다 길면 짜른다 \n",
        "    if len(tmpstr) > SEQ_LEN :\n",
        "        tmpstr = tmpstr[:SEQ_LEN]\n",
        "\n",
        "    # SEQ_LEN보다 작으면 padding\n",
        "    else :\n",
        "        tmpstr = np.pad(tmpstr, (0, SEQ_LEN - len(tmpstr)), 'constant', constant_values = sp_src.pad_id())\n",
        "    \n",
        "    return tmpstr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeyT2TyGSzr8",
        "outputId": "a2143962-e16e-4393-896d-8c6adc1ab1f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6823,    20,  4819,    80,  3222,    51,    80, 16146, 31952,\n",
              "         649,    20, 31760,   301, 31952,   649,    20,  3867,    56,\n",
              "       31952,   649,    20,  1475,    80,   649,    20,  3414, 31952,\n",
              "         372,  3085, 31952,   372,  7886, 31952,   649,    20, 25790,\n",
              "        6930,  6787, 31952,    80,    20, 10726, 10477,  3997, 31952,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# src_data는 data['src']를 참조한다. (동일 id)\n",
        "src_data = data['src']\n",
        "\n",
        "src_list = []\n",
        "for item in src_data:\n",
        "    src_list.append(en_encode(item))\n",
        "\n",
        "src_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrpUSWasSzr8",
        "outputId": "183c0967-5209-4d9d-d50f-f1a212100c51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1269683, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "src_data = np.array(src_list)\n",
        "src_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbG6UIt4Szr9",
        "outputId": "e1568951-d29b-48e1-e0db-247eef665f6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "103"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "import gc\n",
        "del(src_list)\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoyUWrCcSzr9"
      },
      "source": [
        "## TRG Data (KO) Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "iLdTNJnESzr-"
      },
      "outputs": [],
      "source": [
        "def ko_encode(tmpstr: str) -> np.array:\n",
        "    tmpstr = np.array(sp_trg.EncodeAsIds(tmpstr))\n",
        "    tmpstr = np.insert(tmpstr, 0, sp_trg.bos_id())\n",
        "\n",
        "    if len(tmpstr) >= SEQ_LEN:\n",
        "        # SEQ_LEN -1의 길이로 자른다\n",
        "        tmpstr = tmpstr[:SEQ_LEN-1]\n",
        "        # 마지막에 <eos> 토큰을 넣어줌으로써, 길이를 SEQ_LEN으로 맞춘다\n",
        "        tmpstr = np.pad(tmpstr, (0, 1),\n",
        "                        'constant', constant_values=sp_trg.eos_id())\n",
        "\n",
        "\n",
        "    else:\n",
        "        tmpstr = np.pad(tmpstr, (0, 1),\n",
        "                        'constant', constant_values=sp_trg.eos_id())\n",
        "        tmpstr = np.pad(tmpstr, (0, SEQ_LEN - len(tmpstr)),\n",
        "                        'constant', constant_values=sp_trg.pad_id())\n",
        "\n",
        "    return tmpstr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su8a905VSzr-",
        "outputId": "eacdd9c6-10b5-4c54-c5ce-946042bc4941"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    2,   721, 30905, 30546, 11101,    24, 30900, 30558,   130,\n",
              "       30970, 31043,  2579, 28212,  1207,   490, 30600,  2024,  5312,\n",
              "       29426,   548, 15377, 23537,   168, 11300, 30546,  3611, 30841,\n",
              "       30551, 29426,     3,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# trg_data는 data['trg']를 참조한다. (동일 id)\n",
        "trg_data = data['trg']\n",
        "\n",
        "trg_list = []\n",
        "for item in trg_data:\n",
        "    trg_list.append(ko_encode(item))\n",
        "\n",
        "trg_list[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFK1FrZSSzr_",
        "outputId": "b3442bc6-8256-41a8-a330-47f073e4f8ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1269683, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "trg_data = np.array(trg_list)\n",
        "trg_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooy_eIWaSzr_",
        "outputId": "4bf90125-f070-4615-e36b-32351a328ecb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "import gc\n",
        "del(data)\n",
        "del(trg_list)\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDY5iOWVSzr_"
      },
      "source": [
        "# Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "QBtsviGgSzsA"
      },
      "outputs": [],
      "source": [
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, src_data, trg_data):\n",
        "        super().__init__()\n",
        "\n",
        "        assert len(src_data) == len(trg_data)\n",
        "\n",
        "        self.src_data = src_data[:TRAIN_LEN]\n",
        "        self.trg_data = trg_data[:TRAIN_LEN]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(src_data)\n",
        "        \n",
        "    def __getitem__ (self, idx):\n",
        "        src = src_data[idx]\n",
        "        trg_input = trg_data[idx]\n",
        "        trg_output = trg_input[1:SEQ_LEN]\n",
        "        trg_output = np.pad(trg_output, (0,1), 'constant', constant_values =0)\n",
        "        # (seq_len,)\n",
        "        return src, trg_input, trg_output\n",
        "\n",
        "train_dataset = TrainDataset(src_data, trg_data)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle= True, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_ps365AhRBEB"
      },
      "outputs": [],
      "source": [
        "class ValidDataset(Dataset):\n",
        "    def __init__(self, src_data, trg_data):\n",
        "        super().__init__()\n",
        "\n",
        "        assert len(src_data) == len(trg_data)\n",
        "\n",
        "        self.src_data = src_data[TRAIN_LEN:]\n",
        "        self.trg_data = trg_data[TRAIN_LEN:]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(src_data)\n",
        "        \n",
        "    def __getitem__ (self, idx):\n",
        "        src = src_data[idx]\n",
        "        trg_input = trg_data[idx]\n",
        "        trg_output = trg_input[1:SEQ_LEN]\n",
        "        trg_output = np.pad(trg_output, (0,1), 'constant',constant_values= 0)\n",
        "\n",
        "        return src, trg_input, trg_output\n",
        "\n",
        "valid_dataset = ValidDataset(src_data, trg_data)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle= True, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for step, (src, trg_input, trg_output) in enumerate(train_dataloader):\n",
        "  print(src.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jC2Atae8VTjU",
        "outputId": "bee3a026-1aab-4393-972e-1a41221db82f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 200])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFoLlW9DSzsA"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqaL9w0VSzsA"
      },
      "source": [
        "## Mask Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "bunvi9rNSzsA"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Mask 행렬을 반환하는 Mask Function\n",
        "\n",
        "Input\n",
        "- Tensor\n",
        "    shape (bs, seq_len)\n",
        "\n",
        "Args\n",
        "- Option\n",
        "    If option is 'padding', function returns padding mask\n",
        "    If option is 'lookahead', function returns lookahead mask\n",
        "\n",
        "Output\n",
        "- Tensor\n",
        "    shpae (bs, seq_len, seq_len)\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "def makeMask(tensor, option: str) -> torch.Tensor:\n",
        "\n",
        "    '''\n",
        "    tensor (bs, seq_len)\n",
        "    '''\n",
        "    if option == 'padding':\n",
        "        tmp = torch.full_like(tensor, fill_value=PAD_IDX).to(device)\n",
        "        # tmp : (bs,seq_len)\n",
        "        mask = (tensor != tmp).float()\n",
        "        # mask : (bs, seq_len)\n",
        "        mask = repeat(mask, 'bs seq_len -> bs new_axis seq_len ',\n",
        "                      new_axis=mask.shape[1])\n",
        "        # mask(bs,seq_len,seq_len)\n",
        "\n",
        "        '''\n",
        "        Example of mask\n",
        "        tensor([[\n",
        "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
        "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
        "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
        "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
        "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
        "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
        "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
        "         [1., 1., 1., 1., 0., 0., 0., 0.]]])\n",
        "        '''\n",
        "\n",
        "    elif option == 'lookahead':\n",
        "        padding_mask = makeMask(tensor, 'padding')\n",
        "\n",
        "        mask = torch.ones_like(padding_mask)\n",
        "        mask = torch.tril(mask)\n",
        "        '''\n",
        "        Example of 'mask'\n",
        "        tensor([[\n",
        "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
        "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
        "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
        "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
        "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
        "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
        "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
        "        [1., 1., 1., 1., 1., 1., 1., 1.]]])\n",
        "        '''\n",
        "\n",
        "        mask = mask * padding_mask\n",
        "\n",
        "        '''\n",
        "        Example\n",
        "        tensor([[\n",
        "         [1., 0., 0., 0., 0., 0., 0., 0.],\n",
        "         [1., 1., 0., 0., 0., 0., 0., 0.],\n",
        "         [1., 1., 1., 0., 0., 0., 0., 0.],\n",
        "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
        "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
        "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
        "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
        "         [1., 1., 1., 1., 0., 0., 0., 0.]]])\n",
        "        '''\n",
        "\n",
        "\n",
        "    return mask\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb-AM2f2SzsB"
      },
      "source": [
        "## Positional Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Xc96DvV_SzsB"
      },
      "outputs": [],
      "source": [
        "# def pos_embed(input):\n",
        "    # input : (bs, seq_len, hidden_dim)\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loi-qIjHSzsB"
      },
      "source": [
        "## Multihead Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "OacFbmDGSzsB"
      },
      "outputs": [],
      "source": [
        "class Multiheadattention(nn.Module):\n",
        "    def __init__(self, hidden_dim: int, num_head: int):\n",
        "        super().__init__()\n",
        "\n",
        "        # embedding_dim, d_model, 512 in paper\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # 8 in paper\n",
        "        self.num_head = num_head\n",
        "        # head_dim, d_key, d_query, d_value, 64 in paper (= 512 / 8)\n",
        "        self.head_dim = hidden_dim // num_head\n",
        "        self.scale = torch.sqrt(torch.FloatTensor()).to(device)\n",
        "\n",
        "        self.fcQ = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fcK = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fcV = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fcOut = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, srcQ, srcK, srcV, mask=None):\n",
        "\n",
        "        ##### SCALED DOT PRODUCT ATTENTION ######\n",
        "\n",
        "        # input : (bs, seq_len, hidden_dim)\n",
        "        Q = self.fcQ(srcQ)\n",
        "        K = self.fcK(srcK)\n",
        "        V = self.fcV(srcV)\n",
        "\n",
        "        Q = rearrange(\n",
        "            Q, 'bs seq_len (num_head head_dim) -> bs num_head seq_len head_dim', num_head=self.num_head)\n",
        "        K_T = rearrange(\n",
        "            K, 'bs seq_len (num_head head_dim) -> bs num_head head_dim seq_len', num_head=self.num_head)\n",
        "        V = rearrange(\n",
        "            V, 'bs seq_len (num_head head_dim) -> bs num_head seq_len head_dim', num_head=self.num_head)\n",
        "\n",
        "        attention_energy = torch.matmul(Q, K_T)\n",
        "        # attention_energy : (bs, num_head, seq_len, seq_len)\n",
        "\n",
        "        if mask is not None :\n",
        "            attention_energy : torch.masked_fill(attention_energy, (mask==0), -1e10)\n",
        "\n",
        "        attention_energy = torch.softmax(attention_energy, dim = -1)\n",
        "        # print(attention_energy[0,0,0,:])\n",
        "\n",
        "        result = torch.matmul(attention_energy,V)\n",
        "        # result (bs, num_head, seq_len, head_dim)\n",
        "\n",
        "        ##### END OF SCALED DOT PRODUCT ATTENTION ######\n",
        "\n",
        "        # CONCAT\n",
        "        result = rearrange(result, 'bs num_head seq_len head_dim -> bs seq_len (num_head head_dim)')\n",
        "        # result : (bs, seq_len, hidden_dim)\n",
        "\n",
        "        # LINEAR\n",
        "\n",
        "        result = self.fcOut(result)\n",
        "\n",
        "        return result\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "5JrWZEYOSzsC"
      },
      "outputs": [],
      "source": [
        "# # TEST CODE #\n",
        "# bs = 32\n",
        "# seq_len = 200\n",
        "# hidden_dim = 128\n",
        "# test_tensor = torch.randn((bs,seq_len,hidden_dim))\n",
        "# print(test_tensor.shape)\n",
        "# test_layer = Multiheadattention(hidden_dim=hidden_dim, num_head =2)\n",
        "# print(test_layer(srcQ = test_tensor, srcK = test_tensor, srcV = test_tensor).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTb9C0UTSzsC"
      },
      "source": [
        "## Poistionwise Feedforward Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "en_h1fTISzsC"
      },
      "outputs": [],
      "source": [
        "class FFN(nn.Module):\n",
        "    def __init__ (self, hidden_dim, inner_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        # 512 in paper \n",
        "        self.hidden_dim = hidden_dim\n",
        "        # 2048 in paper\n",
        "        self.inner_dim = inner_dim \n",
        "\n",
        "        self.fc1 = nn.Linear(hidden_dim, inner_dim)\n",
        "        self.fc2 = nn.Linear(inner_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        \n",
        "    def forward(self, input):\n",
        "        output = self.fc1(input)\n",
        "        output = self.relu(output)\n",
        "        output = self.fc2(output)\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emd_xbYPSzsD"
      },
      "source": [
        "## Encoder Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "3_d7aGzFSzsD"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, num_head, inner_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_head = num_head\n",
        "        self.inner_dim = inner_dim\n",
        "        \n",
        "        self.multiheadattention = Multiheadattention(hidden_dim, num_head)\n",
        "        self.ffn = FFN(hidden_dim, inner_dim)\n",
        "        self.layerNorm = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(p=0.1)\n",
        "        self.dropout2 = nn.Dropout(p=0.1)\n",
        "\n",
        "\n",
        "    def forward(self, input, mask = None):\n",
        "\n",
        "        # input : (bs, seq_len, hidden_dim)\n",
        "        \n",
        "        # encoder attention\n",
        "        # uses only padding mask\n",
        "        output = self.multiheadattention(srcQ= input, srcK = input, srcV = input, mask = mask)\n",
        "        output = self.dropout1(output)\n",
        "        output = input + output\n",
        "        output = self.layerNorm(output)\n",
        "\n",
        "        output_ = self.ffn(output)\n",
        "        output_ = self.dropout2(output_)\n",
        "        output = output + output_\n",
        "        output = self.layerNorm(output)\n",
        "\n",
        "        # output : (bs, seq_len, hidden_dim)\n",
        "        return output\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0NInjRrSzsD"
      },
      "source": [
        "## Encoder Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Ln84_dJKSzsD"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__ (self, N, hidden_dim, num_head, inner_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        # N : number of encoder layer repeated \n",
        "        self.N = N\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_head = num_head\n",
        "        self.inner_dim = inner_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(num_embeddings=VOCAB_SIZE, embedding_dim=hidden_dim, padding_idx=0)\n",
        "\n",
        "        self.enc_layer1 = EncoderLayer(hidden_dim, num_head, inner_dim)\n",
        "        self.enc_layer2 = EncoderLayer(hidden_dim, num_head, inner_dim)\n",
        "        self.enc_layer3 = EncoderLayer(hidden_dim, num_head, inner_dim)\n",
        "        self.enc_layer4 = EncoderLayer(hidden_dim, num_head, inner_dim)\n",
        "        self.enc_layer5 = EncoderLayer(hidden_dim, num_head, inner_dim)\n",
        "        self.enc_layer6 = EncoderLayer(hidden_dim, num_head, inner_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        # input : (bs, seq_len)\n",
        "\n",
        "        mask = makeMask(input, option='padding')\n",
        "\n",
        "        # embedding layer\n",
        "        output = self.embedding(input)\n",
        "        # output : (bs, seq_len, hidden_dim)\n",
        "\n",
        "        # Positional Embedding\n",
        "        # output = pos_embed(output)\n",
        "\n",
        "        # Dropout\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        # N encoder layer\n",
        "        output = self.enc_layer1(output, mask)\n",
        "        output = self.enc_layer2(output, mask)\n",
        "        output = self.enc_layer3(output, mask)\n",
        "        output = self.enc_layer4(output, mask)\n",
        "        output = self.enc_layer5(output, mask)\n",
        "        output = self.enc_layer6(output, mask)\n",
        "\n",
        "\n",
        "\n",
        "        # output : (bs, seq_len, hidden_dim)\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRhfhEB-SzsE"
      },
      "source": [
        "## Decoder Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "vpUTcWneSzsE"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, num_head, inner_dim):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_head = num_head\n",
        "        self.inner_dim = inner_dim\n",
        "\n",
        "        self.multiheadattention1 = Multiheadattention(hidden_dim, num_head)\n",
        "        self.layerNorm1 = nn.LayerNorm(hidden_dim)\n",
        "        self.multiheadattention2 = Multiheadattention(hidden_dim, num_head)\n",
        "        self.layerNorm2 = nn.LayerNorm(hidden_dim)\n",
        "        self.ffn = FFN(hidden_dim, inner_dim)\n",
        "        self.layerNorm3 = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(p=0.1)\n",
        "        self.dropout2 = nn.Dropout(p=0.1)\n",
        "        self.dropout3 = nn.Dropout(p=0.1)\n",
        "\n",
        "    \n",
        "    def forward(self, input, enc_output, paddingMask, lookaheadMask):\n",
        "        # input : (bs, seq_len, hidden_dim)\n",
        "\n",
        "        # first multiheadattention\n",
        "        output = self.multiheadattention1(input, input, input, lookaheadMask)\n",
        "        output = self.dropout1(output)\n",
        "        output += input\n",
        "        output = self.layerNorm1(output)\n",
        "\n",
        "        # second multiheadattention\n",
        "        output_ = self.multiheadattention2(output, enc_output, enc_output, paddingMask)\n",
        "        output_ = self.dropout2(output_)\n",
        "        output += output_\n",
        "        output = self.layerNorm2(output)\n",
        "\n",
        "        # Feedforward Network\n",
        "        output_ = self.ffn(output)\n",
        "        output_ = self.dropout3(output_)\n",
        "        output += output_\n",
        "        output = self.layerNorm3(output)\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACUVck9eSzsE"
      },
      "source": [
        "## Decoder Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dXokLRkjSzsE"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__ (self, N, hidden_dim, num_head, inner_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        # N : number of encoder layer repeated \n",
        "        self.N = N\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_head = num_head\n",
        "        self.inner_dim = inner_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(num_embeddings=VOCAB_SIZE, embedding_dim=hidden_dim, padding_idx=0)\n",
        "\n",
        "\n",
        "\n",
        "        self.dec_layer1 = DecoderLayer(hidden_dim, num_head, inner_dim)\n",
        "        self.dec_layer2 = DecoderLayer(hidden_dim, num_head, inner_dim)\n",
        "        self.dec_layer3 = DecoderLayer(hidden_dim, num_head, inner_dim)\n",
        "        self.dec_layer4 = DecoderLayer(hidden_dim, num_head, inner_dim)\n",
        "        self.dec_layer5 = DecoderLayer(hidden_dim, num_head, inner_dim)\n",
        "        self.dec_layer6 = DecoderLayer(hidden_dim, num_head, inner_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        \n",
        "        self.finalFc = nn.Linear(hidden_dim, VOCAB_SIZE)\n",
        "\n",
        "\n",
        "    def forward(self, input, enc_src, enc_output):\n",
        "\n",
        "        # input : (bs, seq_len)\n",
        "        # enc_src : (bs, seq_len)\n",
        "        # enc_output : (bs, seq_len,hidden_dim)\n",
        "\n",
        "        lookaheadMask = makeMask(input, option='lookahead')\n",
        "        paddingMask = makeMask(enc_src, option = 'padding')\n",
        "\n",
        "        # embedding layer\n",
        "        output = self.embedding(input)\n",
        "\n",
        "        # Positional Embedding\n",
        "        # output = pos_embed(output)\n",
        "\n",
        "        # Dropout\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        # N decoder layer\n",
        "        output = self.dec_layer1(output,enc_output,paddingMask, lookaheadMask)\n",
        "        output = self.dec_layer2(output,enc_output,paddingMask, lookaheadMask)\n",
        "        output = self.dec_layer3(output,enc_output,paddingMask, lookaheadMask)\n",
        "        output = self.dec_layer4(output,enc_output,paddingMask, lookaheadMask)\n",
        "        output = self.dec_layer5(output,enc_output,paddingMask, lookaheadMask)\n",
        "        output = self.dec_layer6(output,enc_output,paddingMask, lookaheadMask)\n",
        "        # output : (bs, seq_len, hidden_dim)\n",
        "\n",
        "        logits = self.finalFc(output)\n",
        "        # logits : (bs, seq_len, VOCAB_SIZE)\n",
        "        logits = torch.softmax(logits, dim = -1)\n",
        "\n",
        "        output = torch.argmax(logits, dim = -1)\n",
        "        # output : (bs, seq_len)\n",
        "\n",
        "\n",
        "\n",
        "        return output, logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgOKqiCdSzsF"
      },
      "source": [
        "## Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "DhoHNUHPSzsF"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, N = 6, hidden_dim = 512, num_head = 8, inner_dim = 2048):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(N, hidden_dim, num_head, inner_dim)\n",
        "        self.decoder = Decoder(N, hidden_dim, num_head, inner_dim)\n",
        "\n",
        "    def forward(self, enc_src, dec_src):\n",
        "        enc_output = self.encoder(enc_src)\n",
        "        output, logits = self.decoder(dec_src, enc_src, enc_output)\n",
        "        # logits = (bs, seq_len, VOCAB_SIZE) \n",
        "\n",
        "        return output, logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJhmIN-QSzsF"
      },
      "source": [
        "# Model Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fywH11aFSzsF"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "UkQQSxnhSzsF"
      },
      "outputs": [],
      "source": [
        "model = Transformer().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H35nu2mHSzsF"
      },
      "source": [
        "### Weight Init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "rzoP52AVRBEH"
      },
      "outputs": [],
      "source": [
        "for param in model.named_parameters():\n",
        "    if 'weight' in param[0] and 'layerNorm' not in param[0] :\n",
        "        torch.nn.init.xavier_uniform_(param[1])\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBFeBnwHSzsG"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Q8L264UYSzsG"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(params = model.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OI124S8rRBEI"
      },
      "source": [
        "## Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "b1LfUu55RBEI"
      },
      "outputs": [],
      "source": [
        "def criterion(logits: torch.tensor, targets: torch.tensor):\n",
        "    return nn.CrossEntropyLoss()(logits.view(-1,VOCAB_SIZE), targets.view(-1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XEBeN4NRBEI"
      },
      "source": [
        "## Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "xHMJ5lROSzsG"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
        "    # train 모드로 변경\n",
        "    model.train()\n",
        "\n",
        "    # for the Mixed Precision\n",
        "    # Pytorch 예제 : https://pytorch.org/docs/stable/notes/amp_examples.html#amp-examples\n",
        "    scaler = amp.GradScaler()\n",
        "\n",
        "    dataset_size = 0\n",
        "    running_loss = 0\n",
        "\n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "\n",
        "    for step, (src, trg_input, trg_output) in bar:\n",
        "        src = src.to(device)\n",
        "        trg_input = trg_input.to(device)\n",
        "        trg_output = trg_output.to(device)\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "\n",
        "        with amp.autocast(enabled=True):\n",
        "            # logits (bs, seq_len, VOCAB_SIZE)\n",
        "            # trg_output (bs, seq_len)\n",
        "            output, logits = model(enc_src = src, dec_src = trg_input)\n",
        "            loss = criterion(logits, trg_output)\n",
        "\n",
        "        # loss를 Scale\n",
        "        # Scaled Grdients를 계산(call)하기 위해 scaled loss를 backward()\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
        "        # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
        "        # otherwise, optimizer.step() is skipped.\n",
        "        scaler.step(optimizer)\n",
        "        \n",
        "        # Updates the scale for next iteration.\n",
        "        scaler.update()\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # change learning rate by Scheduler\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        # loss.item()은 loss를 Python Float으로 반환\n",
        "        # loss.item()은 batch data의 average loss이므로, sum of loss를 구하기 위해 batch_size를 곱해준다\n",
        "        running_loss += loss.item() * batch_size\n",
        "        dataset_size += batch_size\n",
        "\n",
        "        epoch_loss = running_loss / dataset_size\n",
        "\n",
        "        bar.set_postfix(\n",
        "            Epoch=epoch, Train_Loss=epoch_loss, LR=optimizer.param_groups[0][\"lr\"]\n",
        "        )\n",
        "\n",
        "    # Garbage Collector\n",
        "    gc.collect()\n",
        "\n",
        "    return epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "jbwnuTo7RBEJ"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def valid_one_epoch(model, dataloader, device, epoch):\n",
        "    model.eval()\n",
        "\n",
        "    dataset_size = 0\n",
        "    running_loss = 0\n",
        "\n",
        "    TARGETS = []\n",
        "    PREDS = []\n",
        "\n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "\n",
        "    for step, (src, trg_input, trg_output) in bar:\n",
        "        src = src.to(device, dtype=torch.float)\n",
        "        trg_input = trg_input.to(device, dytpe=torch.float)\n",
        "        trg_output = trg_output.to(device, dtype=torch.float)\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "\n",
        "        output, logits = model(enc_src = src, dec_src = trg_input)\n",
        "        loss = criterion(logits, trg_output)\n",
        "\n",
        "        running_loss += loss.item() * batch_size\n",
        "        dataset_size += batch_size\n",
        "\n",
        "        # 실시간으로 정보를 표시하기 위한 epoch loss\n",
        "        epoch_loss = running_loss / dataset_size\n",
        "\n",
        "        PREDS.append(output.view(-1,VOCAB_SIZE).cpu().detach().numpy())\n",
        "        TARGETS.append(logits.view(-1).cpu().detach().numpy())\n",
        "\n",
        "        bar.set_postfix(\n",
        "            Epoch=epoch, Valid_Loss=epoch_loss, LR=optimizer.param_groups[0][\"lr\"]\n",
        "        )\n",
        "\n",
        "    TARGETS = np.concatenate(TARGETS)\n",
        "    PREDS = np.concatenate(PREDS)\n",
        "    # 실제 epoch loss는 다음과 같이 계산한다\n",
        "    val_loss = criterion(PREDS, TARGETS)\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    return epoch_loss, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "fIT6cHpsRBEJ"
      },
      "outputs": [],
      "source": [
        "def run_training(\n",
        "    model,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    device,\n",
        "    num_epochs,\n",
        "    metric_prefix=\"\",\n",
        "    file_prefix=\"\",\n",
        "    early_stopping=True,\n",
        "    early_stopping_step=10,\n",
        "):\n",
        "    # To automatically log graidents\n",
        "    wandb.watch(model, log_freq=100)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"[INFO] Using GPU:{}\\n\".format(torch.cuda.get_device_name()))\n",
        "\n",
        "    start = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = np.inf\n",
        "    history = defaultdict(list)\n",
        "    early_stop_counter = 0\n",
        "\n",
        "    # num_epochs만큼, train과 val을 실행한다\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        gc.collect()\n",
        "\n",
        "        train_epoch_loss = train_one_epoch(\n",
        "            model,\n",
        "            optimizer,\n",
        "            scheduler,\n",
        "            dataloader= train_dataloader,\n",
        "            device=device,\n",
        "            epoch=epoch,\n",
        "        )\n",
        "\n",
        "        val_epoch_loss, val_loss = valid_one_epoch(\n",
        "            model, valid_dataloader, device=device, epoch=epoch\n",
        "        )\n",
        "\n",
        "        history[f\"{metric_prefix}Train Loss\"].append(train_epoch_loss)\n",
        "        history[f\"{metric_prefix}Valid Epoch Loss\"].append(val_epoch_loss)\n",
        "        history[f\"{metric_prefix}Valid Loss\"].append(val_loss)\n",
        "\n",
        "        # Log the metrics\n",
        "        wandb.log(\n",
        "            {\n",
        "                f\"{metric_prefix}Train Loss\": train_epoch_loss,\n",
        "                f\"{metric_prefix}Valid Loss\": val_epoch_loss,\n",
        "                f\"{metric_prefix}Valid RMSE\": val_loss,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        print(f\"Valid Loss : {val_loss}\")\n",
        "\n",
        "        # deep copy the model\n",
        "        if val_loss <= best_loss:\n",
        "            early_stop_counter = 0\n",
        "\n",
        "            print(\n",
        "                f\"Validation Loss improved( {best_loss} ---> {val_loss}  )\"\n",
        "            )\n",
        "\n",
        "            # Update Best Loss\n",
        "            best_loss = val_loss\n",
        "            \n",
        "            # Update Best Model Weight\n",
        "            # run.summary['Best RMSE'] = best_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            PATH = \"{}epoch{:.0f}_Loss{:.4f}.bin\".format(file_prefix, epoch, best_loss)\n",
        "            torch.save(model.state_dict(), PATH)\n",
        "            torch.save(model.state_dict(), f\"{file_prefix}best_{epoch}epoch.bin\")\n",
        "            # Save a model file from the current directory\n",
        "            wandb.save(PATH)\n",
        "\n",
        "            print(f\"Model Saved\")\n",
        "\n",
        "        elif early_stopping:\n",
        "            early_stop_counter += 1\n",
        "            if early_stop_counter > early_stopping_step:\n",
        "                break\n",
        "\n",
        "        print()\n",
        "\n",
        "    end = time.time()\n",
        "    time_elapsed = end - start\n",
        "    print(\n",
        "        \"Training complete in {:.0f}h {:.0f}m {:.0f}s\".format(\n",
        "            time_elapsed // 3600,\n",
        "            (time_elapsed % 3600) // 60,\n",
        "            (time_elapsed % 3600) % 60,\n",
        "        )\n",
        "    )\n",
        "    print(\"Best Loss: {:.4f}\".format(best_loss))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCqLo1s4RBEJ",
        "outputId": "9860e093-0ea1-4d59-a1fa-bb81f1d9bb7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using GPU:Tesla K80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 43/39678 [03:39<56:15:30,  5.11s/it, Epoch=1, LR=0.001, Train_Loss=9.66]"
          ]
        }
      ],
      "source": [
        "run_training(\n",
        "    model = model,\n",
        "    optimizer = optimizer,\n",
        "    scheduler = None,\n",
        "    device = device,\n",
        "    num_epochs = 20,\n",
        "    metric_prefix=\"\",\n",
        "    file_prefix=\"\",\n",
        "    early_stopping=True,\n",
        "    early_stopping_step=10,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVufCm3-SzsG"
      },
      "source": [
        "# Inference"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "transformer.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "9aea7b6a7444b8f7906e49a0ee5a1a1954c47b5d0459b9029b34272caa5266f3"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('base': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}