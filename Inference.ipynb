{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Library\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:15:19.897728Z","iopub.status.busy":"2022-01-11T14:15:19.897423Z","iopub.status.idle":"2022-01-11T14:15:31.388554Z","shell.execute_reply":"2022-01-11T14:15:31.387358Z","shell.execute_reply.started":"2022-01-11T14:15:19.897690Z"},"trusted":true},"outputs":[],"source":["! pip install sentencepiece einops wandb torch-summary icecream -qq\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:15:31.390914Z","iopub.status.busy":"2022-01-11T14:15:31.390647Z","iopub.status.idle":"2022-01-11T14:15:35.066138Z","shell.execute_reply":"2022-01-11T14:15:35.065117Z","shell.execute_reply.started":"2022-01-11T14:15:31.390878Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","from pprint import pprint\n","# from konlpy.tag import Mecab\n","from nltk.tokenize import word_tokenize as en_tokenizer\n","import sentencepiece as spm\n","import urllib.request\n","import csv\n","import numpy as np\n","from einops import rearrange, reduce, repeat\n","from torch.cuda import amp\n","from tqdm import tqdm\n","import wandb\n","import time\n","import copy\n","from collections import defaultdict\n","from sklearn.metrics import mean_squared_error\n","import joblib\n","import gc\n","import os\n","from icecream import ic\n","from sklearn.model_selection import train_test_split\n","import os\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:15:35.067826Z","iopub.status.busy":"2022-01-11T14:15:35.067608Z","iopub.status.idle":"2022-01-11T14:15:35.078908Z","shell.execute_reply":"2022-01-11T14:15:35.077972Z","shell.execute_reply.started":"2022-01-11T14:15:35.067801Z"},"trusted":true},"outputs":[],"source":["TRAIN_PATH = './train'\n","VOCAB_SIZE = 10000\n","SEQ_LEN = 60\n","\n","\n","PAD_IDX = 0\n","BOS_IDX = 2\n","EOS_IDX = 3\n","\n","\n","# ENV = 'COLAB'\n","ENV = 'KAGGLE'\n","# ENV = 'SYSTEM'\n","\n","# Option for Mixed Precision\n","# FP16 = True\n","FP16 = False\n","\n","N = 3\n","HIDDEN_DIM = 128\n","NUM_HEAD = 8\n","INNER_DIM = 256\n","BATCH_SIZE = 32\n","\n","CONFIG = {\n","    'VOCAB_SIZE': VOCAB_SIZE,\n","    'SEQ_LEN': SEQ_LEN,\n","    'N': N,\n","    'HIDDEN_DIM': HIDDEN_DIM,\n","    'NUM_HEAD': NUM_HEAD,\n","    'INNER_DIM': INNER_DIM,\n","    'BATCH_SIZE': BATCH_SIZE,\n","}\n","\n","\n","if 'device' not in globals():\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f'Using {device}')\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:16:53.769759Z","iopub.status.busy":"2022-01-11T14:16:53.768811Z","iopub.status.idle":"2022-01-11T14:17:07.222101Z","shell.execute_reply":"2022-01-11T14:17:07.221152Z","shell.execute_reply.started":"2022-01-11T14:16:53.769708Z"},"trusted":true},"outputs":[],"source":["import wandb\n","run = wandb.init()\n","dataset = wandb.run.use_artifact(\n","    'jiwon7258/Transformer_bible/bible-dataset_10000_60:latest', type='dataset')\n","# Download the artifact's contents\n","artifact_dir = dataset.download()\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:16:17.297290Z","iopub.status.busy":"2022-01-11T14:16:17.297053Z","iopub.status.idle":"2022-01-11T14:16:17.302292Z","shell.execute_reply":"2022-01-11T14:16:17.301602Z","shell.execute_reply.started":"2022-01-11T14:16:17.297262Z"},"trusted":true},"outputs":[],"source":["if (ENV == 'COLAB'):\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n"]},{"cell_type":"markdown","metadata":{},"source":["  # Load"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:17:45.150750Z","iopub.status.busy":"2022-01-11T14:17:45.150010Z","iopub.status.idle":"2022-01-11T14:17:45.155585Z","shell.execute_reply":"2022-01-11T14:17:45.155000Z","shell.execute_reply.started":"2022-01-11T14:17:45.150701Z"},"trusted":true},"outputs":[],"source":["DATASET_PATH = './'\n","if (ENV == 'KAGGLE'):\n","    DATASET_PATH = '../input/enko-bible'\n","elif (ENV == 'COLAB'):\n","    DATASET_PATH = '/content/drive/MyDrive/notebooks/transformer_bible/'"]},{"cell_type":"markdown","metadata":{},"source":["   # 영어 데이터 로드"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:17:45.157821Z","iopub.status.busy":"2022-01-11T14:17:45.157348Z","iopub.status.idle":"2022-01-11T14:17:45.263103Z","shell.execute_reply":"2022-01-11T14:17:45.262065Z","shell.execute_reply.started":"2022-01-11T14:17:45.157788Z"},"trusted":true},"outputs":[],"source":["en_train = open(os.path.join(DATASET_PATH, 'bible-all.en.txt'))\n","en_train_content = en_train.read()\n"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:17:45.264747Z","iopub.status.busy":"2022-01-11T14:17:45.264403Z","iopub.status.idle":"2022-01-11T14:17:45.279811Z","shell.execute_reply":"2022-01-11T14:17:45.278820Z","shell.execute_reply.started":"2022-01-11T14:17:45.264712Z"},"trusted":true},"outputs":[],"source":["en_train_list = en_train_content.split('\\n')\n"]},{"cell_type":"markdown","metadata":{},"source":["   # 한국어 데이터 로드"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:17:45.282061Z","iopub.status.busy":"2022-01-11T14:17:45.281281Z","iopub.status.idle":"2022-01-11T14:17:45.453841Z","shell.execute_reply":"2022-01-11T14:17:45.453120Z","shell.execute_reply.started":"2022-01-11T14:17:45.282004Z"},"trusted":true},"outputs":[],"source":["ko_train = open(os.path.join(DATASET_PATH, 'bible-all.kr.txt'))\n","ko_train_content = ko_train.read()"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:17:45.457029Z","iopub.status.busy":"2022-01-11T14:17:45.456548Z","iopub.status.idle":"2022-01-11T14:17:45.471449Z","shell.execute_reply":"2022-01-11T14:17:45.470271Z","shell.execute_reply.started":"2022-01-11T14:17:45.456993Z"},"trusted":true},"outputs":[],"source":["ko_train_list = ko_train_content.split('\\n')"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:17:45.474470Z","iopub.status.busy":"2022-01-11T14:17:45.473219Z","iopub.status.idle":"2022-01-11T14:17:45.487723Z","shell.execute_reply":"2022-01-11T14:17:45.486890Z","shell.execute_reply.started":"2022-01-11T14:17:45.474422Z"},"trusted":true},"outputs":[],"source":["en_train_list[:10]"]},{"cell_type":"markdown","metadata":{},"source":["   # DATA 데이터프레임"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:17:45.489740Z","iopub.status.busy":"2022-01-11T14:17:45.489149Z","iopub.status.idle":"2022-01-11T14:17:45.537462Z","shell.execute_reply":"2022-01-11T14:17:45.536798Z","shell.execute_reply.started":"2022-01-11T14:17:45.489707Z"},"trusted":true},"outputs":[],"source":["data = pd.DataFrame()\n","data['en_raw'] = en_train_list\n","data['ko_raw'] = ko_train_list"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:17:45.539185Z","iopub.status.busy":"2022-01-11T14:17:45.538757Z","iopub.status.idle":"2022-01-11T14:17:45.556631Z","shell.execute_reply":"2022-01-11T14:17:45.556014Z","shell.execute_reply.started":"2022-01-11T14:17:45.539138Z"},"trusted":true},"outputs":[],"source":["data.head()"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:17:45.558300Z","iopub.status.busy":"2022-01-11T14:17:45.557928Z","iopub.status.idle":"2022-01-11T14:17:45.563078Z","shell.execute_reply":"2022-01-11T14:17:45.562463Z","shell.execute_reply.started":"2022-01-11T14:17:45.558261Z"},"trusted":true},"outputs":[],"source":["len(data)\n"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:17:45.564680Z","iopub.status.busy":"2022-01-11T14:17:45.564324Z","iopub.status.idle":"2022-01-11T14:17:45.588480Z","shell.execute_reply":"2022-01-11T14:17:45.587624Z","shell.execute_reply.started":"2022-01-11T14:17:45.564643Z"},"trusted":true},"outputs":[],"source":["data = data.reset_index(drop = True)\n","data.head()"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:17:45.590148Z","iopub.status.busy":"2022-01-11T14:17:45.589903Z","iopub.status.idle":"2022-01-11T14:17:46.163862Z","shell.execute_reply":"2022-01-11T14:17:46.162986Z","shell.execute_reply.started":"2022-01-11T14:17:45.590116Z"},"trusted":true},"outputs":[],"source":["data['en'] = data['en_raw'].apply(lambda x: x.split(' ')[1:])\n","data['en'] = data['en'].apply(lambda x: (' ').join(x))\n","data['ko'] = data['ko_raw'].apply(lambda x: x.split(' ')[1:])\n","data['ko'] = data['ko'].apply(lambda x: (' ').join(x))\n"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:17:46.165471Z","iopub.status.busy":"2022-01-11T14:17:46.165227Z","iopub.status.idle":"2022-01-11T14:17:46.185941Z","shell.execute_reply":"2022-01-11T14:17:46.185259Z","shell.execute_reply.started":"2022-01-11T14:17:46.165443Z"},"trusted":true},"outputs":[],"source":["data = data[['en','ko']]\n","data.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Transformer\n"]},{"cell_type":"markdown","metadata":{},"source":["## Mask Function\n"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:17:46.187558Z","iopub.status.busy":"2022-01-11T14:17:46.187214Z","iopub.status.idle":"2022-01-11T14:17:46.197096Z","shell.execute_reply":"2022-01-11T14:17:46.196385Z","shell.execute_reply.started":"2022-01-11T14:17:46.187528Z"},"trusted":true},"outputs":[],"source":["'''\n","Mask 행렬을 반환하는 Mask Function\n","Masking은 QK_T 중 srcK 의 seq_len을 중심으로 한다는 점을 알아두자!!\n","\n","Input\n","- Tensor\n","    shape (bs, srcK seq_len)\n","\n","Args\n","- Option\n","    If option is 'padding', function returns padding mask\n","    If option is 'lookahead', function returns lookahead mask\n","\n","Output\n","- Tensor (option = 'padding' )\n","    shape (bs, 1, 1, srcK seq_len)\n","\n","\n","* shape 중 (1, 1) 부분은 broad casting을 위한 것이다.\n","'''\n","\n","\n","def makeMask(tensor, option: str) -> torch.Tensor:\n","    '''\n","    tensor (bs, seq_len)\n","    '''\n","    if option == 'padding':\n","        tmp = torch.full_like(tensor, fill_value=PAD_IDX).to(device)\n","        # tmp : (bs,seq_len)\n","        mask = (tensor != tmp).float()\n","        # mask : (bs, seq_len)\n","        mask = rearrange(mask, 'bs seq_len -> bs 1 1 seq_len ')\n","\n","        # mask(bs, 1, seq_len,seq_len)\n","\n","        '''\n","        Example of mask\n","        tensor([[\n","         [1., 1., 1., 1., 0., 0., 0., 0.]]])\n","        '''\n","\n","    elif option == 'lookahead':\n","        # srcQ의 seq_len과 srcK의 seq_len이 동일하다고 가정한다\n","        # tensor : (bs, seq_len)\n","\n","        padding_mask = makeMask(tensor, 'padding')\n","        padding_mask = repeat(\n","            padding_mask, 'bs 1 1 k_len -> bs 1 new k_len', new=padding_mask.shape[3])\n","        # padding_mask : (bs, 1, seq_len, seq_len)\n","\n","        '''\n","        Example of padding_mask\n","        tensor([[\n","         [1., 1., 1., 1., 0., 0., 0., 0.]\n","         [1., 1., 1., 1., 0., 0., 0., 0.]\n","         [1., 1., 1., 1., 0., 0., 0., 0.]\n","         [1., 1., 1., 1., 0., 0., 0., 0.]\n","         [1., 1., 1., 1., 0., 0., 0., 0.]\n","         [1., 1., 1., 1., 0., 0., 0., 0.]\n","         [1., 1., 1., 1., 0., 0., 0., 0.]\n","         [1., 1., 1., 1., 0., 0., 0., 0.]]])\n","        '''\n","        mask = torch.ones_like(padding_mask)\n","        mask = torch.tril(mask)\n","\n","        '''\n","        Example of 'mask'\n","        tensor([[\n","        [1., 0., 0., 0., 0., 0., 0., 0.],\n","        [1., 1., 0., 0., 0., 0., 0., 0.],\n","        [1., 1., 1., 0., 0., 0., 0., 0.],\n","        [1., 1., 1., 1., 0., 0., 0., 0.],\n","        [1., 1., 1., 1., 1., 0., 0., 0.],\n","        [1., 1., 1., 1., 1., 1., 0., 0.],\n","        [1., 1., 1., 1., 1., 1., 1., 0.],\n","        [1., 1., 1., 1., 1., 1., 1., 1.]]])\n","        '''\n","\n","        mask = mask * padding_mask\n","        # ic(mask.shape)\n","\n","        '''\n","        Example\n","        tensor([[\n","         [1., 0., 0., 0., 0., 0., 0., 0.],\n","         [1., 1., 0., 0., 0., 0., 0., 0.],\n","         [1., 1., 1., 0., 0., 0., 0., 0.],\n","         [1., 1., 1., 1., 0., 0., 0., 0.],\n","         [1., 1., 1., 1., 0., 0., 0., 0.],\n","         [1., 1., 1., 1., 0., 0., 0., 0.],\n","         [1., 1., 1., 1., 0., 0., 0., 0.],\n","         [1., 1., 1., 1., 0., 0., 0., 0.]]])\n","        '''\n","\n","    return mask\n"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:17:46.200551Z","iopub.status.busy":"2022-01-11T14:17:46.199737Z","iopub.status.idle":"2022-01-11T14:17:46.215079Z","shell.execute_reply":"2022-01-11T14:17:46.214248Z","shell.execute_reply.started":"2022-01-11T14:17:46.200514Z"},"trusted":true},"outputs":[],"source":["# test = torch.Tensor([[1,2,3,4,5,6,0,0,0,0]])\n","# ic(test.shape)\n","# test1 = makeMask(test, option = 'padding')\n","# test2 = makeMask(test, option = 'lookahead')\n","# ic(test1.shape)\n","# ic(test2.shape)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Multihead Attention\n"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:17:46.216790Z","iopub.status.busy":"2022-01-11T14:17:46.216536Z","iopub.status.idle":"2022-01-11T14:17:46.230872Z","shell.execute_reply":"2022-01-11T14:17:46.229935Z","shell.execute_reply.started":"2022-01-11T14:17:46.216759Z"},"trusted":true},"outputs":[],"source":["class Multiheadattention(nn.Module):\n","    def __init__(self, hidden_dim: int, num_head: int):\n","        super().__init__()\n","\n","        # embedding_dim, d_model, 512 in paper\n","        self.hidden_dim = hidden_dim\n","        # 8 in paper\n","        self.num_head = num_head\n","        # head_dim, d_key, d_query, d_value, 64 in paper (= 512 / 8)\n","        self.head_dim = hidden_dim // num_head\n","        self.scale = torch.sqrt(torch.FloatTensor()).to(device)\n","\n","        self.fcQ = nn.Linear(hidden_dim, hidden_dim)\n","        self.fcK = nn.Linear(hidden_dim, hidden_dim)\n","        self.fcV = nn.Linear(hidden_dim, hidden_dim)\n","        self.fcOut = nn.Linear(hidden_dim, hidden_dim)\n","\n","        self.dropout = nn.Dropout(0.1)\n","\n","    def forward(self, srcQ, srcK, srcV, mask=None):\n","\n","        ##### SCALED DOT PRODUCT ATTENTION ######\n","\n","        # input : (bs, seq_len, hidden_dim)\n","        Q = self.fcQ(srcQ)\n","        K = self.fcK(srcK)\n","        V = self.fcV(srcV)\n","\n","        Q = rearrange(\n","            Q, 'bs seq_len (num_head head_dim) -> bs num_head seq_len head_dim', num_head=self.num_head)\n","        K_T = rearrange(\n","            K, 'bs seq_len (num_head head_dim) -> bs num_head head_dim seq_len', num_head=self.num_head)\n","        V = rearrange(\n","            V, 'bs seq_len (num_head head_dim) -> bs num_head seq_len head_dim', num_head=self.num_head)\n","\n","        attention_energy = torch.matmul(Q, K_T)\n","        # attention_energy : (bs, num_head, q_len, k_len)\n","\n","        if mask is not None:\n","            '''\n","            mask.shape\n","            if padding : (bs, 1, 1, k_len)\n","            if lookahead : (bs, 1, q_len, k_len)\n","            '''\n","            attention_energy = torch.masked_fill(\n","                attention_energy, (mask == 0), -1e+4)\n","\n","        attention_energy = torch.softmax(attention_energy, dim=-1)\n","\n","        result = torch.matmul(self.dropout(attention_energy), V)\n","        # result (bs, num_head, seq_len, head_dim)\n","\n","        ##### END OF SCALED DOT PRODUCT ATTENTION ######\n","\n","        # CONCAT\n","        result = rearrange(\n","            result, 'bs num_head seq_len head_dim -> bs seq_len (num_head head_dim)')\n","        # result : (bs, seq_len, hidden_dim)\n","\n","        # LINEAR\n","\n","        result = self.fcOut(result)\n","\n","        return result\n"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:17:46.233023Z","iopub.status.busy":"2022-01-11T14:17:46.232494Z","iopub.status.idle":"2022-01-11T14:17:46.248173Z","shell.execute_reply":"2022-01-11T14:17:46.247260Z","shell.execute_reply.started":"2022-01-11T14:17:46.232972Z"},"trusted":true},"outputs":[],"source":["# # TEST CODE #\n","# bs = 1\n","# seq_len = 10\n","# hidden_dim = 256\n","# # src = torch.Tensor([[   2, 1568,  955,  612,  221,   64,   20, 8905,  928, 8768,  167, 8841,\n","# #          3834,    9, 1687,   41, 7661,  562, 9073, 5204, 8794, 8931,   14, 8823,\n","# #          5616, 1289, 8793, 2477,  438,   27, 8783,   14, 8905,  534,  235,  204,\n","# #          9037, 8745, 9040, 6942,   47, 8738,    3,    0,    0,    0,    0,    0,\n","# #             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]])\n","# src = torch.Tensor([[1,2,3,4,5,6,0,0,0,0]])\n","\n","# padding_mask = makeMask(src, option = 'padding')\n","# ic(padding_mask.shape)\n","# lookahead_mask = makeMask(src, option = 'lookahead')\n","# ic(lookahead_mask.shape)\n","\n","\n","# test_Q = torch.randn((bs,2,hidden_dim))\n","# test_K = torch.randn((bs, 10, hidden_dim))\n","# ic(test_Q.shape)\n","# test_layer = Multiheadattention(hidden_dim=hidden_dim, num_head =8)\n","# ic(test_layer(srcQ = test_Q, srcK = test_K, srcV = test_K, mask = padding_mask).shape)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Poistionwise Feedforward Network\n"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:17:46.249785Z","iopub.status.busy":"2022-01-11T14:17:46.249518Z","iopub.status.idle":"2022-01-11T14:17:46.267157Z","shell.execute_reply":"2022-01-11T14:17:46.266109Z","shell.execute_reply.started":"2022-01-11T14:17:46.249739Z"},"trusted":true},"outputs":[],"source":["class FFN(nn.Module):\n","    def __init__(self, hidden_dim, inner_dim):\n","        super().__init__()\n","\n","        # 512 in paper\n","        self.hidden_dim = hidden_dim\n","        # 2048 in paper\n","        self.inner_dim = inner_dim\n","\n","        self.fc1 = nn.Linear(hidden_dim, inner_dim)\n","        self.fc2 = nn.Linear(inner_dim, hidden_dim)\n","        self.relu = nn.ReLU(inplace=False)\n","        self.dropout = nn.Dropout(0.1)\n","\n","    def forward(self, input):\n","        output = input\n","        output = self.fc1(output)\n","        output2 = self.relu(output)\n","        output2 = self.dropout(output)\n","        output3 = self.fc2(output2)\n","\n","        return output3\n"]},{"cell_type":"markdown","metadata":{},"source":["## Encoder Layer\n"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:17:46.269767Z","iopub.status.busy":"2022-01-11T14:17:46.268919Z","iopub.status.idle":"2022-01-11T14:17:46.280544Z","shell.execute_reply":"2022-01-11T14:17:46.279900Z","shell.execute_reply.started":"2022-01-11T14:17:46.269718Z"},"trusted":true},"outputs":[],"source":["class EncoderLayer(nn.Module):\n","    def __init__(self, hidden_dim, num_head, inner_dim):\n","        super().__init__()\n","\n","        self.hidden_dim = hidden_dim\n","        self.num_head = num_head\n","        self.inner_dim = inner_dim\n","\n","        self.multiheadattention = Multiheadattention(hidden_dim, num_head)\n","        self.ffn = FFN(hidden_dim, inner_dim)\n","        self.layerNorm1 = nn.LayerNorm(hidden_dim)\n","        self.layerNorm2 = nn.LayerNorm(hidden_dim)\n","\n","        self.dropout1 = nn.Dropout(p=0.1)\n","        self.dropout2 = nn.Dropout(p=0.1)\n","\n","    def forward(self, input, mask=None):\n","\n","        # input : (bs, seq_len, hidden_dim)\n","\n","        # encoder attention\n","        # uses only padding mask\n","        output = self.multiheadattention(\n","            srcQ=input, srcK=input, srcV=input, mask=mask)\n","        output = self.dropout1(output)\n","        output = input + output\n","        output = self.layerNorm1(output)\n","\n","        output_ = self.ffn(output)\n","        output_ = self.dropout2(output_)\n","        output = output + output_\n","        output = self.layerNorm2(output)\n","\n","        # output : (bs, seq_len, hidden_dim)\n","        return output\n"]},{"cell_type":"markdown","metadata":{},"source":["## Encoder Architecture\n"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:17:46.283153Z","iopub.status.busy":"2022-01-11T14:17:46.281981Z","iopub.status.idle":"2022-01-11T14:17:46.303905Z","shell.execute_reply":"2022-01-11T14:17:46.303146Z","shell.execute_reply.started":"2022-01-11T14:17:46.283107Z"},"trusted":true},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, N, hidden_dim, num_head, inner_dim, max_length=100):\n","        super().__init__()\n","\n","        # N : number of encoder layer repeated\n","        self.N = N\n","        self.hidden_dim = hidden_dim\n","        self.num_head = num_head\n","        self.inner_dim = inner_dim\n","\n","        self.embedding = nn.Embedding(\n","            num_embeddings=VOCAB_SIZE, embedding_dim=hidden_dim, padding_idx=0)\n","        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n","        self.enc_layers = nn.ModuleList(\n","            [EncoderLayer(hidden_dim, num_head, inner_dim) for _ in range(N)])\n","\n","        self.dropout = nn.Dropout(p=0.1)\n","\n","    def forward(self, input):\n","\n","        batch_size = input.shape[0]\n","        seq_len = input.shape[1]\n","        # input : (bs, seq_len)\n","\n","        mask = makeMask(input, option='padding')\n","\n","        pos = torch.arange(0, seq_len).unsqueeze(\n","            0).repeat(batch_size, 1).to(device)\n","        # pos: [batch_size, src_len]\n","\n","        # embedding layer\n","        output = self.dropout(self.embedding(input) + self.pos_embedding(pos))\n","        # output : (bs, seq_len, hidden_dim)\n","\n","        # Positional Embedding\n","        # output = pos_embed(output)\n","\n","        # Dropout\n","        output = self.dropout(output)\n","\n","        # N encoder layer\n","        for layer in self.enc_layers:\n","            output = layer(output, mask)\n","\n","        # output : (bs, seq_len, hidden_dim)\n","\n","        return output\n"]},{"cell_type":"markdown","metadata":{},"source":["## Decoder Layer\n"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:17:46.306264Z","iopub.status.busy":"2022-01-11T14:17:46.305792Z","iopub.status.idle":"2022-01-11T14:17:46.322671Z","shell.execute_reply":"2022-01-11T14:17:46.321902Z","shell.execute_reply.started":"2022-01-11T14:17:46.306217Z"},"trusted":true},"outputs":[],"source":["class DecoderLayer(nn.Module):\n","    def __init__(self, hidden_dim, num_head, inner_dim):\n","        super().__init__()\n","        self.hidden_dim = hidden_dim\n","        self.num_head = num_head\n","        self.inner_dim = inner_dim\n","\n","        self.multiheadattention1 = Multiheadattention(hidden_dim, num_head)\n","        self.layerNorm1 = nn.LayerNorm(hidden_dim)\n","        self.multiheadattention2 = Multiheadattention(hidden_dim, num_head)\n","        self.layerNorm2 = nn.LayerNorm(hidden_dim)\n","        self.ffn = FFN(hidden_dim, inner_dim)\n","        self.layerNorm3 = nn.LayerNorm(hidden_dim)\n","\n","        self.dropout1 = nn.Dropout(p=0.1)\n","        self.dropout2 = nn.Dropout(p=0.1)\n","        self.dropout3 = nn.Dropout(p=0.1)\n","\n","    def forward(self, input, enc_output, paddingMask, lookaheadMask):\n","        # input : (bs, seq_len, hidden_dim)\n","        # enc_output : (bs, seq_len, hidden_dim)\n","\n","        # first multiheadattention\n","        output = self.multiheadattention1(input, input, input, lookaheadMask)\n","        output = self.dropout1(output)\n","        output = output + input\n","        output = self.layerNorm1(output)\n","\n","        # second multiheadattention\n","        output_ = self.multiheadattention2(\n","            output, enc_output, enc_output, paddingMask)\n","        output_ = self.dropout2(output_)\n","        output = output_ + output\n","        output = self.layerNorm2(output)\n","\n","        # Feedforward Network\n","        output_ = self.ffn(output)\n","        output_ = self.dropout3(output_)\n","        output = output + output_\n","        output = self.layerNorm3(output)\n","\n","        return output\n"]},{"cell_type":"markdown","metadata":{},"source":["## Decoder Architecture\n"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:17:46.324301Z","iopub.status.busy":"2022-01-11T14:17:46.323697Z","iopub.status.idle":"2022-01-11T14:17:46.341698Z","shell.execute_reply":"2022-01-11T14:17:46.341038Z","shell.execute_reply.started":"2022-01-11T14:17:46.324267Z"},"trusted":true},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, N, hidden_dim, num_head, inner_dim, max_length=100):\n","        super().__init__()\n","\n","        # N : number of encoder layer repeated\n","        self.N = N\n","        self.hidden_dim = hidden_dim\n","        self.num_head = num_head\n","        self.inner_dim = inner_dim\n","\n","        self.embedding = nn.Embedding(\n","            num_embeddings=VOCAB_SIZE, embedding_dim=hidden_dim, padding_idx=0)\n","        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n","\n","        self.dec_layers = nn.ModuleList(\n","            [DecoderLayer(hidden_dim, num_head, inner_dim) for _ in range(N)])\n","\n","        self.dropout = nn.Dropout(p=0.1)\n","\n","        self.finalFc = nn.Linear(hidden_dim, VOCAB_SIZE)\n","\n","    def forward(self, input, enc_src, enc_output):\n","\n","        # input = dec_src : (bs, seq_len)\n","        # enc_src : (bs, seq_len)\n","        # enc_output : (bs, seq_len,hidden_dim)\n","\n","        lookaheadMask = makeMask(input, option='lookahead')\n","        paddingMask = makeMask(enc_src, option='padding')\n","\n","        # embedding layer\n","        output = self.embedding(input)\n","        # output = (bs, seq_len, hidden_dim)\n","\n","        # Positional Embedding\n","        # output = pos_embed(output)\n","\n","        # Dropout\n","        output = self.dropout(output)\n","\n","        # N decoder layer\n","        for layer in self.dec_layers:\n","            output = layer(output, enc_output, paddingMask, lookaheadMask)\n","        # output : (bs, seq_len, hidden_dim)\n","\n","        logits = self.finalFc(output)\n","        # logits : (bs, seq_len, VOCAB_SIZE)\n","        output = torch.softmax(logits, dim=-1)\n","\n","        output = torch.argmax(output, dim=-1)\n","        # output : (bs, seq_len), dtype=int64\n","\n","        return logits, output\n"]},{"cell_type":"markdown","metadata":{},"source":["# Transformer\n"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:17:46.343175Z","iopub.status.busy":"2022-01-11T14:17:46.342792Z","iopub.status.idle":"2022-01-11T14:17:46.357366Z","shell.execute_reply":"2022-01-11T14:17:46.356405Z","shell.execute_reply.started":"2022-01-11T14:17:46.343144Z"},"trusted":true},"outputs":[],"source":["class Transformer(nn.Module):\n","    def __init__(self, N=2, hidden_dim=256, num_head=8, inner_dim=512):\n","        super().__init__()\n","        self.encoder = Encoder(N, hidden_dim, num_head, inner_dim)\n","        self.decoder = Decoder(N, hidden_dim, num_head, inner_dim)\n","\n","    def forward(self, enc_src, dec_src):\n","        # enc_src : (bs, seq_len)\n","        # dec_src : (bs, seq_len)\n","\n","        # print(f'enc_src : {enc_src.shape}')\n","        # print(f'dec_src : {dec_src.shape}')\n","\n","        enc_output = self.encoder(enc_src)\n","        # enc_output : (bs, seq_len, hidden_dim)\n","        logits, output = self.decoder(dec_src, enc_src, enc_output)\n","        # logits = (bs, seq_len, VOCAB_SIZE)\n","\n","        return logits, output\n"]},{"cell_type":"markdown","metadata":{},"source":["# Inference\n"]},{"cell_type":"markdown","metadata":{},"source":["## Load Model\n"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:18:31.929146Z","iopub.status.busy":"2022-01-11T14:18:31.928740Z","iopub.status.idle":"2022-01-11T14:18:32.688214Z","shell.execute_reply":"2022-01-11T14:18:32.687149Z","shell.execute_reply.started":"2022-01-11T14:18:31.929109Z"},"trusted":true},"outputs":[],"source":["# Download Saved Model Weight\n","WEIGHT_FILE = 'final.bin'\n","WEIGHT_PATH = './weight'\n","WEIGHT_RUN_PATH = 'jiwon7258/Transformer_bible/3rzi4gl9'\n","\n","wandb.restore(WEIGHT_FILE, run_path=WEIGHT_RUN_PATH, root=WEIGHT_PATH)\n","\n","\n","# Load Sentencedpiece Trained Model\n","SRC_MODEL_FILE = os.path.join(artifact_dir,'src.model')\n","TRG_MODEL_FILE = os.path.join(artifact_dir,'trg.model')\n"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:18:32.690239Z","iopub.status.busy":"2022-01-11T14:18:32.690016Z","iopub.status.idle":"2022-01-11T14:18:32.711409Z","shell.execute_reply":"2022-01-11T14:18:32.710559Z","shell.execute_reply.started":"2022-01-11T14:18:32.690211Z"},"trusted":true},"outputs":[],"source":["sp_src = spm.SentencePieceProcessor()\n","sp_src.Load(SRC_MODEL_FILE)\n","sp_trg = spm.SentencePieceProcessor()\n","sp_trg.Load(TRG_MODEL_FILE)\n"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:19:58.456802Z","iopub.status.busy":"2022-01-11T14:19:58.456515Z","iopub.status.idle":"2022-01-11T14:19:58.544683Z","shell.execute_reply":"2022-01-11T14:19:58.543953Z","shell.execute_reply.started":"2022-01-11T14:19:58.456772Z"},"trusted":true},"outputs":[],"source":["%%capture output\n","model = Transformer(N, HIDDEN_DIM, NUM_HEAD, INNER_DIM).to(device)\n","model.load_state_dict(torch.load(os.path.join(WEIGHT_PATH, WEIGHT_FILE), map_location=device))\n","model.eval()\n"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:19:58.546771Z","iopub.status.busy":"2022-01-11T14:19:58.546501Z","iopub.status.idle":"2022-01-11T14:19:58.557657Z","shell.execute_reply":"2022-01-11T14:19:58.556698Z","shell.execute_reply.started":"2022-01-11T14:19:58.546737Z"},"trusted":true},"outputs":[],"source":["def predict(src_sentence):\n","    # Prepare Sample Sentence\n","    dec_sentence = ''\n","\n","    enc_src = sp_src.EncodeAsIds(src_sentence)\n","    dec_src = []\n","    dec_src = np.insert(dec_src, 0, sp_trg.bos_id())\n","    # dec_src = ko_encode(dec_sentence)\n","\n","    enc_src = torch.Tensor(enc_src).view(1, -1).int().to(device)\n","    dec_src = torch.Tensor(dec_src).view(1, -1).int().to(device)\n","    # enc_src : (1,seq_len)\n","    # dec_src : (1,seq_len)\n","\n","    last_token = None\n","    last_token_idx = 0\n","\n","    while(True):\n","\n","        # dec_src에 dec_output의 last token을 추가합니다\n","        enc_output = model.encoder(enc_src)\n","        # enc_output : (1,seq_len, hidden_dim)\n","\n","        dec_logits, dec_output = model.decoder(\n","            input=dec_src, enc_src=enc_src, enc_output=enc_output\n","        )\n","        # dec_output : (1,seq_len)\n","        # dec_logits : (1, seq_len, VOCAB_SIZE)\n","\n","        last_token = dec_output[:, last_token_idx].item()\n","        last_token = torch.Tensor([last_token]).view(-1, 1).int()\n","\n","        # last_token : (1, 1)\n","        dec_src = torch.cat((dec_src, last_token), dim=-1)\n","\n","        last_token_idx = last_token_idx + 1\n","\n","        # print(dec_src)\n","        # print(sp_trg.Decode(dec_src.tolist()))\n","        # print(last_token.item())\n","        if last_token.item() is EOS_IDX:\n","            break\n","\n","    # ic(dec_src.tolist())\n","    return sp_trg.Decode(dec_src.tolist())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T14:19:58.560120Z","iopub.status.busy":"2022-01-11T14:19:58.559163Z"},"trusted":true},"outputs":[],"source":["# Prepare 10 Sample Sentence\n","indices = np.random.choice(len(data['en']), 10, replace=False)\n","sentences = data['en'][indices].to_list()\n","answers = data['ko'][indices].to_list()\n","\n","for idx in range(len(sentences)):\n","    sentence = sentences[idx]\n","    print(f'en = {sentence}')\n","    print(f'answer = {answers[idx]}')\n","    print(f'ko = {predict(sentence)}')\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
