{"cells":[{"cell_type":"markdown","metadata":{},"source":["   # Library\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:38:58.03436Z","iopub.status.busy":"2022-01-11T16:38:58.034055Z","iopub.status.idle":"2022-01-11T16:39:08.633661Z","shell.execute_reply":"2022-01-11T16:39:08.632741Z","shell.execute_reply.started":"2022-01-11T16:38:58.034271Z"},"trusted":true},"outputs":[],"source":["! pip install sentencepiece einops wandb torch-summary icecream -qq"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:08.636264Z","iopub.status.busy":"2022-01-11T16:39:08.63589Z","iopub.status.idle":"2022-01-11T16:39:11.830575Z","shell.execute_reply":"2022-01-11T16:39:11.829692Z","shell.execute_reply.started":"2022-01-11T16:39:08.636224Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","from pprint import pprint\n","from nltk.tokenize import word_tokenize as en_tokenizer\n","import sentencepiece as spm\n","import urllib.request\n","import csv\n","import numpy as np\n","from einops import rearrange, reduce, repeat\n","from torch.cuda import amp\n","from tqdm import tqdm\n","import wandb\n","import time\n","import copy\n","from collections import defaultdict\n","from sklearn.metrics import mean_squared_error\n","import joblib\n","import gc\n","import os\n","from icecream import ic\n","from sklearn.model_selection import train_test_split\n","import os\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:11.832739Z","iopub.status.busy":"2022-01-11T16:39:11.832478Z","iopub.status.idle":"2022-01-11T16:39:11.884151Z","shell.execute_reply":"2022-01-11T16:39:11.88343Z","shell.execute_reply.started":"2022-01-11T16:39:11.832704Z"},"trusted":true},"outputs":[],"source":["VOCAB_SIZE = 10000\n","SEQ_LEN = 60\n","\n","\n","PAD_IDX = 0\n","BOS_IDX = 2\n","SOS_IDX = 3\n","\n","\n","\n","# ENV = 'COLAB'\n","ENV = 'KAGGLE'\n","# ENV = 'SYSTEM'\n","\n","# Option for Mixed Precision\n","FP16 = True\n","# FP16 = False\n","\n","N = 2\n","HIDDEN_DIM = 256\n","NUM_HEAD = 8 \n","INNER_DIM = 512\n","BATCH_SIZE = 64\n","LEARNING_RATE = 1e-4\n","WEIGHT_DECAY = 0\n","\n","\n","CONFIG = {\n","    'VOCAB_SIZE': VOCAB_SIZE,\n","    'SEQ_LEN': SEQ_LEN,\n","    'N': N,\n","    'HIDDEN_DIM': HIDDEN_DIM,\n","    'NUM_HEAD': NUM_HEAD,\n","    'INNER_DIM': INNER_DIM,\n","    'BATCH_SIZE': BATCH_SIZE,\n","    'WEIGHT_DECAY' : WEIGHT_DECAY,\n","    'LEARNING_RATE' : LEARNING_RATE,\n","}\n","\n","\n","if 'device' not in globals():\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f'Using {device}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:11.888289Z","iopub.status.busy":"2022-01-11T16:39:11.887742Z","iopub.status.idle":"2022-01-11T16:39:20.016947Z","shell.execute_reply":"2022-01-11T16:39:20.016083Z","shell.execute_reply.started":"2022-01-11T16:39:11.888246Z"},"trusted":true},"outputs":[],"source":["import wandb\n","import os\n","# if want to run in offline mode\n","\n","# os.environ[\"WANDB_MODE\"] = \"dryrun\"\n","# wandb.init(project=\"Transformer_bible\", entity=\"jiwon7258\")\n","\n","\n","os.environ[\"WANDB_MODE\"] = \"online\"\n","wandb.init(project=\"Transformer_bible\", entity=\"jiwon7258\", config = CONFIG, job_type = 'train')\n","wandb.run.name = f\"train_{VOCAB_SIZE}_{SEQ_LEN}_{N}_{HIDDEN_DIM}_{INNER_DIM}\"\n","\n","\n","dataset = wandb.Artifact(f'bible-dataset_{VOCAB_SIZE}_{SEQ_LEN}', type='dataset')\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["  # Load"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:20.020176Z","iopub.status.busy":"2022-01-11T16:39:20.019894Z","iopub.status.idle":"2022-01-11T16:39:22.586074Z","shell.execute_reply":"2022-01-11T16:39:22.585373Z","shell.execute_reply.started":"2022-01-11T16:39:20.020146Z"},"trusted":true},"outputs":[],"source":["dataset = wandb.run.use_artifact(f'bible-dataset_{VOCAB_SIZE}_{SEQ_LEN}:latest')\n","\n","# Download the artifact's contents\n","artifact_dir = dataset.download()\n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:22.589788Z","iopub.status.busy":"2022-01-11T16:39:22.589184Z","iopub.status.idle":"2022-01-11T16:39:26.220112Z","shell.execute_reply":"2022-01-11T16:39:26.219359Z","shell.execute_reply.started":"2022-01-11T16:39:22.589747Z"},"trusted":true},"outputs":[],"source":["# or Train / Valid Data\n","src_train_path = os.path.join(artifact_dir,'src_train.pkl')\n","src_valid_path = os.path.join(artifact_dir,'src_valid.pkl')\n","trg_train_path = os.path.join(artifact_dir,'trg_train.pkl')\n","trg_valid_path = os.path.join(artifact_dir,'trg_valid.pkl')\n","\n","src_train = joblib.load(src_train_path)\n","src_valid = joblib.load(src_valid_path)\n","trg_train = joblib.load(trg_train_path)\n","trg_valid = joblib.load(trg_valid_path)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["   # Create Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:26.222003Z","iopub.status.busy":"2022-01-11T16:39:26.221756Z","iopub.status.idle":"2022-01-11T16:39:26.234883Z","shell.execute_reply":"2022-01-11T16:39:26.234241Z","shell.execute_reply.started":"2022-01-11T16:39:26.221969Z"},"trusted":true},"outputs":[],"source":["class TrainDataset(Dataset):\n","    def __init__(self, src_data, trg_data):\n","        super().__init__()\n","\n","        assert len(src_data) == len(trg_data)\n","\n","        self.src_data = src_data\n","        self.trg_data = trg_data\n","\n","    def __len__(self):\n","        return len(self.src_data)\n","        \n","    def __getitem__ (self, idx):\n","        src = self.src_data[idx]\n","        trg_input = self.trg_data[idx]\n","        trg_output = trg_input[1:SEQ_LEN]\n","        trg_output = np.pad(trg_output, (0,1), 'constant', constant_values =0)\n","        # (seq_len,)\n","        return torch.Tensor(src).long(), torch.Tensor(trg_input).long(), torch.Tensor(trg_output).long()\n","\n","train_dataset = TrainDataset(src_train, trg_train)\n","train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle= True, pin_memory=True)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:26.240069Z","iopub.status.busy":"2022-01-11T16:39:26.239579Z","iopub.status.idle":"2022-01-11T16:39:26.448413Z","shell.execute_reply":"2022-01-11T16:39:26.447627Z","shell.execute_reply.started":"2022-01-11T16:39:26.240031Z"},"trusted":true},"outputs":[],"source":["class ValidDataset(Dataset):\n","    def __init__(self, src_data, trg_data):\n","        super().__init__()\n","\n","        assert len(src_data) == len(trg_data)\n","\n","        self.src_data = src_data\n","        self.trg_data = trg_data\n","\n","    def __len__(self):\n","        return len(self.src_data)\n","        \n","    def __getitem__ (self, idx):\n","        src = self.src_data[idx]\n","        trg_input = self.trg_data[idx]\n","        trg_output = trg_input[1:SEQ_LEN]\n","        trg_output = np.pad(trg_output, (0,1), 'constant',constant_values= 0)\n","\n","        return torch.Tensor(src).long(), torch.Tensor(trg_input).long(), torch.Tensor(trg_output).long()\n","\n","valid_dataset = ValidDataset(src_valid, trg_valid)\n","valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle= False, pin_memory=True)\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["   # Transformer"]},{"cell_type":"markdown","metadata":{},"source":["   ## Mask Function"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:26.450694Z","iopub.status.busy":"2022-01-11T16:39:26.45025Z","iopub.status.idle":"2022-01-11T16:39:26.465083Z","shell.execute_reply":"2022-01-11T16:39:26.464364Z","shell.execute_reply.started":"2022-01-11T16:39:26.450656Z"},"trusted":true},"outputs":[],"source":["'''\n","Mask 행렬을 반환하는 Mask Function\n","Masking은 QK_T 중 srcK 의 seq_len을 중심으로 한다는 점을 알아두자!!\n","\n","Input\n","- Tensor\n","    shape (bs, srcK seq_len)\n","\n","Args\n","- Option\n","    If option is 'padding', function returns padding mask\n","    If option is 'lookahead', function returns lookahead mask\n","\n","Output\n","- Tensor (option = 'padding' )\n","    shape (bs, 1, 1, srcK seq_len)\n","\n","\n","* shape 중 (1, 1) 부분은 broad casting을 위한 것이다.\n","'''\n","\n","\n","def makeMask(tensor, option: str) -> torch.Tensor:\n","    '''\n","    tensor (bs, seq_len)\n","    '''\n","    if option == 'padding':\n","        tmp = torch.full_like(tensor, fill_value=PAD_IDX).to(device)\n","        # tmp : (bs,seq_len)\n","        mask = (tensor != tmp).float()\n","        # mask : (bs, seq_len)\n","        mask = rearrange(mask, 'bs seq_len -> bs 1 1 seq_len ')\n","\n","        # mask(bs, 1, seq_len,seq_len)\n","\n","        '''\n","        Example of mask\n","        tensor([[\n","         [1., 1., 1., 1., 0., 0., 0., 0.]]])\n","        '''\n","\n","    elif option == 'lookahead':\n","        # srcQ의 seq_len과 srcK의 seq_len이 동일하다고 가정한다\n","        # tensor : (bs, seq_len)\n","\n","        padding_mask = makeMask(tensor, 'padding')\n","        padding_mask = repeat(\n","            padding_mask, 'bs 1 1 k_len -> bs 1 new k_len', new=padding_mask.shape[3])\n","        # padding_mask : (bs, 1, seq_len, seq_len)\n","\n","        '''\n","        Example of padding_mask\n","        tensor([[\n","         [1., 1., 1., 1., 0., 0., 0., 0.]\n","         [1., 1., 1., 1., 0., 0., 0., 0.]\n","         [1., 1., 1., 1., 0., 0., 0., 0.]\n","         [1., 1., 1., 1., 0., 0., 0., 0.]\n","         [1., 1., 1., 1., 0., 0., 0., 0.]\n","         [1., 1., 1., 1., 0., 0., 0., 0.]\n","         [1., 1., 1., 1., 0., 0., 0., 0.]\n","         [1., 1., 1., 1., 0., 0., 0., 0.]]])\n","        '''\n","        mask = torch.ones_like(padding_mask)\n","        mask = torch.tril(mask)\n","\n","        '''\n","        Example of 'mask'\n","        tensor([[\n","        [1., 0., 0., 0., 0., 0., 0., 0.],\n","        [1., 1., 0., 0., 0., 0., 0., 0.],\n","        [1., 1., 1., 0., 0., 0., 0., 0.],\n","        [1., 1., 1., 1., 0., 0., 0., 0.],\n","        [1., 1., 1., 1., 1., 0., 0., 0.],\n","        [1., 1., 1., 1., 1., 1., 0., 0.],\n","        [1., 1., 1., 1., 1., 1., 1., 0.],\n","        [1., 1., 1., 1., 1., 1., 1., 1.]]])\n","        '''\n","\n","        mask = mask * padding_mask\n","        # ic(mask.shape)\n","\n","        '''\n","        Example\n","        tensor([[\n","         [1., 0., 0., 0., 0., 0., 0., 0.],\n","         [1., 1., 0., 0., 0., 0., 0., 0.],\n","         [1., 1., 1., 0., 0., 0., 0., 0.],\n","         [1., 1., 1., 1., 0., 0., 0., 0.],\n","         [1., 1., 1., 1., 0., 0., 0., 0.],\n","         [1., 1., 1., 1., 0., 0., 0., 0.],\n","         [1., 1., 1., 1., 0., 0., 0., 0.],\n","         [1., 1., 1., 1., 0., 0., 0., 0.]]])\n","        '''\n","\n","    return mask\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:26.466423Z","iopub.status.busy":"2022-01-11T16:39:26.466109Z","iopub.status.idle":"2022-01-11T16:39:26.480917Z","shell.execute_reply":"2022-01-11T16:39:26.480223Z","shell.execute_reply.started":"2022-01-11T16:39:26.466396Z"},"trusted":true},"outputs":[],"source":["# test = torch.Tensor([[1,2,3,4,5,6,0,0,0,0]])\n","# ic(test.shape)\n","# test1 = makeMask(test, option = 'padding')\n","# test2 = makeMask(test, option = 'lookahead')\n","# ic(test1.shape)\n","# ic(test2.shape)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["   ## Multihead Attention"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:26.483943Z","iopub.status.busy":"2022-01-11T16:39:26.483719Z","iopub.status.idle":"2022-01-11T16:39:26.497849Z","shell.execute_reply":"2022-01-11T16:39:26.497081Z","shell.execute_reply.started":"2022-01-11T16:39:26.483915Z"},"trusted":true},"outputs":[],"source":["class Multiheadattention(nn.Module):\n","    def __init__(self, hidden_dim: int, num_head: int):\n","        super().__init__()\n","\n","        # embedding_dim, d_model, 512 in paper\n","        self.hidden_dim = hidden_dim\n","        # 8 in paper\n","        self.num_head = num_head\n","        # head_dim, d_key, d_query, d_value, 64 in paper (= 512 / 8)\n","        self.head_dim = hidden_dim // num_head\n","        self.scale = torch.sqrt(torch.FloatTensor()).to(device)\n","\n","        self.fcQ = nn.Linear(hidden_dim, hidden_dim)\n","        self.fcK = nn.Linear(hidden_dim, hidden_dim)\n","        self.fcV = nn.Linear(hidden_dim, hidden_dim)\n","        self.fcOut = nn.Linear(hidden_dim, hidden_dim)\n","\n","        self.dropout = nn.Dropout(0.1)\n","\n","\n","    def forward(self, srcQ, srcK, srcV, mask=None):\n","\n","        ##### SCALED DOT PRODUCT ATTENTION ######\n","\n","        # input : (bs, seq_len, hidden_dim)\n","        Q = self.fcQ(srcQ)\n","        K = self.fcK(srcK)\n","        V = self.fcV(srcV)\n","\n","        Q = rearrange(\n","            Q, 'bs seq_len (num_head head_dim) -> bs num_head seq_len head_dim', num_head=self.num_head)\n","        K_T = rearrange(\n","            K, 'bs seq_len (num_head head_dim) -> bs num_head head_dim seq_len', num_head=self.num_head)\n","        V = rearrange(\n","            V, 'bs seq_len (num_head head_dim) -> bs num_head seq_len head_dim', num_head=self.num_head)\n","        \n","        attention_energy = torch.matmul(Q, K_T)\n","        # attention_energy : (bs, num_head, q_len, k_len)\n","\n","        if mask is not None :\n","            '''\n","            mask.shape\n","            if padding : (bs, 1, 1, k_len)\n","            if lookahead : (bs, 1, q_len, k_len)\n","            '''\n","            attention_energy = torch.masked_fill(attention_energy, (mask == 0), -1e+4)\n","            \n","        attention_energy = torch.softmax(attention_energy, dim = -1)\n","\n","        result = torch.matmul(self.dropout(attention_energy),V)\n","        # result (bs, num_head, seq_len, head_dim)\n","\n","        ##### END OF SCALED DOT PRODUCT ATTENTION ######\n","\n","        # CONCAT\n","        result = rearrange(result, 'bs num_head seq_len head_dim -> bs seq_len (num_head head_dim)')\n","        # result : (bs, seq_len, hidden_dim)\n","\n","        # LINEAR\n","\n","        result = self.fcOut(result)\n","\n","        return result\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:26.500513Z","iopub.status.busy":"2022-01-11T16:39:26.49882Z","iopub.status.idle":"2022-01-11T16:39:26.509771Z","shell.execute_reply":"2022-01-11T16:39:26.509017Z","shell.execute_reply.started":"2022-01-11T16:39:26.500488Z"},"trusted":true},"outputs":[],"source":["# # TEST CODE #\n","# bs = 1\n","# seq_len = 10\n","# hidden_dim = 10\n","# # src = torch.Tensor([[   2, 1568,  955,  612,  221,   64,   20, 8905,  928, 8768,  167, 8841,\n","# #          3834,    9, 1687,   41, 7661,  562, 9073, 5204, 8794, 8931,   14, 8823,\n","# #          5616, 1289, 8793, 2477,  438,   27, 8783,   14, 8905,  534,  235,  204,\n","# #          9037, 8745, 9040, 6942,   47, 8738,    3,    0,    0,    0,    0,    0,\n","# #             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]])\n","# src = torch.Tensor([[1,2,3,4,5,6,0,0,0,0]])\n","\n","# padding_mask = makeMask(src, option = 'padding')\n","# ic(padding_mask.shape)\n","# lookahead_mask = makeMask(src, option = 'lookahead')\n","# ic(lookahead_mask.shape)\n","\n","\n","# test_Q = torch.randn((bs,2,10))\n","# test_K = rearrange(src, 'seq_len hidden_dim -> 1 seq_len hidden_dim')\n","# test_K = repeat(src, 'seq_len hidden_dim -> 1 (10 seq_len) hidden_dim')\n","# ic(test_Q.shape)\n","# ic(test_K.shape)\n","# test_layer = Multiheadattention(hidden_dim=hidden_dim, num_head =2)\n","# ic(test_layer(srcQ = test_Q, srcK = test_K, srcV = test_K, mask = padding_mask).shape)\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["   ## Poistionwise Feedforward Network"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:26.511611Z","iopub.status.busy":"2022-01-11T16:39:26.511281Z","iopub.status.idle":"2022-01-11T16:39:26.52143Z","shell.execute_reply":"2022-01-11T16:39:26.520761Z","shell.execute_reply.started":"2022-01-11T16:39:26.511516Z"},"trusted":true},"outputs":[],"source":["class FFN(nn.Module):\n","    def __init__ (self, hidden_dim, inner_dim):\n","        super().__init__()\n","\n","        # 512 in paper \n","        self.hidden_dim = hidden_dim\n","        # 2048 in paper\n","        self.inner_dim = inner_dim \n","\n","        self.fc1 = nn.Linear(hidden_dim, inner_dim)\n","        self.fc2 = nn.Linear(inner_dim, hidden_dim)\n","        self.relu = nn.ReLU(inplace=False)\n","        self.dropout = nn.Dropout(0.1)\n","\n","\n","        \n","    def forward(self, input):\n","        output = input\n","        output = self.fc1(output)\n","        output2 = self.relu(output)\n","        output2 = self.dropout(output)\n","        output3 = self.fc2(output2)\n","\n","        return output3\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["   ## Encoder Layer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:26.525596Z","iopub.status.busy":"2022-01-11T16:39:26.525255Z","iopub.status.idle":"2022-01-11T16:39:26.53433Z","shell.execute_reply":"2022-01-11T16:39:26.533637Z","shell.execute_reply.started":"2022-01-11T16:39:26.525564Z"},"trusted":true},"outputs":[],"source":["class EncoderLayer(nn.Module):\n","    def __init__(self, hidden_dim, num_head, inner_dim):\n","        super().__init__()\n","\n","        self.hidden_dim = hidden_dim\n","        self.num_head = num_head\n","        self.inner_dim = inner_dim\n","        \n","        self.multiheadattention = Multiheadattention(hidden_dim, num_head)\n","        self.ffn = FFN(hidden_dim, inner_dim)\n","        self.layerNorm1 = nn.LayerNorm(hidden_dim)\n","        self.layerNorm2 = nn.LayerNorm(hidden_dim)\n","\n","\n","        self.dropout1 = nn.Dropout(p=0.1)\n","        self.dropout2 = nn.Dropout(p=0.1)\n","\n","\n","    def forward(self, input, mask = None):\n","\n","        # input : (bs, seq_len, hidden_dim)\n","        \n","        # encoder attention\n","        # uses only padding mask\n","        output = self.multiheadattention(srcQ= input, srcK = input, srcV = input, mask = mask)\n","        output = self.dropout1(output)\n","        output = input + output\n","        output = self.layerNorm1(output)\n","\n","        output_ = self.ffn(output)\n","        output_ = self.dropout2(output_)\n","        output = output + output_\n","        output = self.layerNorm2(output)\n","\n","        # output : (bs, seq_len, hidden_dim)\n","        return output\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["   ## Encoder Architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:26.536132Z","iopub.status.busy":"2022-01-11T16:39:26.53571Z","iopub.status.idle":"2022-01-11T16:39:26.547826Z","shell.execute_reply":"2022-01-11T16:39:26.547166Z","shell.execute_reply.started":"2022-01-11T16:39:26.536097Z"},"trusted":true},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__ (self, N, hidden_dim, num_head, inner_dim,max_length=100):\n","        super().__init__()\n","\n","        # N : number of encoder layer repeated \n","        self.N = N\n","        self.hidden_dim = hidden_dim\n","        self.num_head = num_head\n","        self.inner_dim = inner_dim\n","\n","        self.embedding = nn.Embedding(num_embeddings=VOCAB_SIZE, embedding_dim=hidden_dim, padding_idx=0)\n","        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n","        self.enc_layers = nn.ModuleList([EncoderLayer(hidden_dim, num_head, inner_dim) for _ in range(N)])\n","\n","        self.dropout = nn.Dropout(p=0.1)\n","\n","\n","\n","    def forward(self, input):\n","        \n","        batch_size = input.shape[0]\n","        seq_len = input.shape[1]\n","        # input : (bs, seq_len)\n","\n","        mask = makeMask(input, option='padding')\n","\n","        pos = torch.arange(0, seq_len).unsqueeze(0).repeat(batch_size, 1).to(device)\n","        # pos: [batch_size, src_len]\n","\n","        # embedding layer\n","        output = self.dropout(self.embedding(input) + self.pos_embedding(pos))\n","        # output : (bs, seq_len, hidden_dim)\n","\n","\n","        # Positional Embedding\n","        # output = pos_embed(output)\n","\n","        # Dropout\n","        output = self.dropout(output)\n","\n","        # N encoder layer\n","        for layer in self.enc_layers:\n","            output = layer(output, mask)\n","\n","        # output : (bs, seq_len, hidden_dim)\n","\n","        return output\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["   ## Decoder Layer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:26.549826Z","iopub.status.busy":"2022-01-11T16:39:26.549224Z","iopub.status.idle":"2022-01-11T16:39:26.562013Z","shell.execute_reply":"2022-01-11T16:39:26.561334Z","shell.execute_reply.started":"2022-01-11T16:39:26.549793Z"},"trusted":true},"outputs":[],"source":["class DecoderLayer(nn.Module):\n","    def __init__(self, hidden_dim, num_head, inner_dim):\n","        super().__init__()\n","        self.hidden_dim = hidden_dim\n","        self.num_head = num_head\n","        self.inner_dim = inner_dim\n","\n","        self.multiheadattention1 = Multiheadattention(hidden_dim, num_head)\n","        self.layerNorm1 = nn.LayerNorm(hidden_dim)\n","        self.multiheadattention2 = Multiheadattention(hidden_dim, num_head)\n","        self.layerNorm2 = nn.LayerNorm(hidden_dim)\n","        self.ffn = FFN(hidden_dim, inner_dim)\n","        self.layerNorm3 = nn.LayerNorm(hidden_dim)\n","\n","        self.dropout1 = nn.Dropout(p=0.1)\n","        self.dropout2 = nn.Dropout(p=0.1)\n","        self.dropout3 = nn.Dropout(p=0.1)\n","\n","    \n","    def forward(self, input, enc_output, paddingMask, lookaheadMask):\n","        # input : (bs, seq_len, hidden_dim)\n","        # enc_output : (bs, seq_len, hidden_dim)\n","\n","        # first multiheadattention\n","        output = self.multiheadattention1(input, input, input, lookaheadMask)\n","        output = self.dropout1(output)\n","        output = output + input\n","        output = self.layerNorm1(output)\n","\n","\n","        # second multiheadattention\n","        output_ = self.multiheadattention2(output, enc_output, enc_output, paddingMask)\n","        output_ = self.dropout2(output_)\n","        output = output_ + output\n","        output = self.layerNorm2(output)\n","\n","\n","\n","        # Feedforward Network\n","        output_ = self.ffn(output)\n","        output_ = self.dropout3(output_)\n","        output = output + output_\n","        output = self.layerNorm3(output)\n","\n","\n","\n","        return output\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["   ## Decoder Architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:26.563609Z","iopub.status.busy":"2022-01-11T16:39:26.563318Z","iopub.status.idle":"2022-01-11T16:39:26.574954Z","shell.execute_reply":"2022-01-11T16:39:26.574281Z","shell.execute_reply.started":"2022-01-11T16:39:26.563575Z"},"trusted":true},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__ (self, N, hidden_dim, num_head, inner_dim, max_length=100):\n","        super().__init__()\n","\n","        # N : number of encoder layer repeated \n","        self.N = N\n","        self.hidden_dim = hidden_dim\n","        self.num_head = num_head\n","        self.inner_dim = inner_dim\n","\n","        self.embedding = nn.Embedding(num_embeddings=VOCAB_SIZE, embedding_dim=hidden_dim, padding_idx=0)\n","        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n","\n","        self.dec_layers = nn.ModuleList([DecoderLayer(hidden_dim, num_head, inner_dim) for _ in range(N)])\n","\n","        self.dropout = nn.Dropout(p=0.1)\n","        \n","        self.finalFc = nn.Linear(hidden_dim, VOCAB_SIZE)\n","\n","\n","    def forward(self, input, enc_src, enc_output):\n","\n","        # input = dec_src : (bs, seq_len)\n","        # enc_src : (bs, seq_len)\n","        # enc_output : (bs, seq_len,hidden_dim)\n","        \n","        lookaheadMask = makeMask(input, option= 'lookahead')\n","        paddingMask = makeMask(enc_src, option = 'padding')\n","\n","        # embedding layer\n","        output = self.embedding(input)\n","        # output = (bs, seq_len, hidden_dim)\n","\n","\n","        # Positional Embedding\n","        # output = pos_embed(output)\n","\n","        # Dropout\n","        output = self.dropout(output)\n","\n","        # N decoder layer\n","        for layer in self.dec_layers:\n","            output = layer(output, enc_output, paddingMask, lookaheadMask)\n","        # output : (bs, seq_len, hidden_dim)\n","\n","        logits = self.finalFc(output)\n","        # logits : (bs, seq_len, VOCAB_SIZE)\n","        output = torch.softmax(logits, dim = -1)\n","\n","        output = torch.argmax(output, dim = -1)\n","        # output : (bs, seq_len), dtype=int64\n","\n","\n","\n","        return logits, output\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["   ## Transformer Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:26.576859Z","iopub.status.busy":"2022-01-11T16:39:26.576322Z","iopub.status.idle":"2022-01-11T16:39:26.593177Z","shell.execute_reply":"2022-01-11T16:39:26.592294Z","shell.execute_reply.started":"2022-01-11T16:39:26.576825Z"},"trusted":true},"outputs":[],"source":["class Transformer(nn.Module):\n","    def __init__(self, N = 2, hidden_dim = 256, num_head = 8, inner_dim = 512):\n","        super().__init__()\n","        self.encoder = Encoder(N, hidden_dim, num_head, inner_dim)\n","        self.decoder = Decoder(N, hidden_dim, num_head, inner_dim)\n","\n","    def forward(self, enc_src, dec_src):\n","        # enc_src : (bs, seq_len)\n","        # dec_src : (bs, seq_len)\n","\n","        # print(f'enc_src : {enc_src.shape}')\n","        # print(f'dec_src : {dec_src.shape}')\n","\n","        enc_output = self.encoder(enc_src)\n","        # enc_output : (bs, seq_len, hidden_dim)\n","        logits, output = self.decoder(dec_src, enc_src, enc_output)\n","        # logits = (bs, seq_len, VOCAB_SIZE) \n","\n","        return logits, output\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["   # Model Train"]},{"cell_type":"markdown","metadata":{},"source":["   # Create Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:26.595447Z","iopub.status.busy":"2022-01-11T16:39:26.594634Z","iopub.status.idle":"2022-01-11T16:39:29.440112Z","shell.execute_reply":"2022-01-11T16:39:29.439354Z","shell.execute_reply.started":"2022-01-11T16:39:26.595413Z"},"trusted":true},"outputs":[],"source":["model = Transformer(N, HIDDEN_DIM, NUM_HEAD, INNER_DIM).to(device)\n","ic.disable()\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["   # Check Model Structure"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:29.441654Z","iopub.status.busy":"2022-01-11T16:39:29.441415Z","iopub.status.idle":"2022-01-11T16:39:30.246075Z","shell.execute_reply":"2022-01-11T16:39:30.245399Z","shell.execute_reply.started":"2022-01-11T16:39:29.441622Z"},"trusted":true},"outputs":[],"source":["from torchsummary import summary\n","test1 = torch.randint(low = 0, high = 1000, size = (SEQ_LEN,))\n","test2 = torch.randint(low = 0, high = 1000, size = (SEQ_LEN,))\n","summary(model, [(SEQ_LEN,), (SEQ_LEN,)], dtypes = [torch.int, torch.int])\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["   # Weight Init"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:30.247919Z","iopub.status.busy":"2022-01-11T16:39:30.247463Z","iopub.status.idle":"2022-01-11T16:39:30.256121Z","shell.execute_reply":"2022-01-11T16:39:30.255457Z","shell.execute_reply.started":"2022-01-11T16:39:30.247883Z"},"trusted":true},"outputs":[],"source":["for param in model.named_parameters():\n","    if 'weight' in param[0] and 'layerNorm' not in param[0] :\n","        torch.nn.init.xavier_uniform_(param[1])"]},{"cell_type":"markdown","metadata":{},"source":["   # Optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:30.25774Z","iopub.status.busy":"2022-01-11T16:39:30.257319Z","iopub.status.idle":"2022-01-11T16:39:30.264363Z","shell.execute_reply":"2022-01-11T16:39:30.263653Z","shell.execute_reply.started":"2022-01-11T16:39:30.257703Z"},"trusted":true},"outputs":[],"source":["optimizer = torch.optim.Adam(params = model.parameters(), lr = LEARNING_RATE, weight_decay = WEIGHT_DECAY)\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["   # Loss Function"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:30.265951Z","iopub.status.busy":"2022-01-11T16:39:30.265315Z","iopub.status.idle":"2022-01-11T16:39:30.271872Z","shell.execute_reply":"2022-01-11T16:39:30.271177Z","shell.execute_reply.started":"2022-01-11T16:39:30.265913Z"},"trusted":true},"outputs":[],"source":["def criterion(logits: torch.tensor, targets: torch.tensor):\n","    return nn.CrossEntropyLoss(ignore_index=PAD_IDX)(logits.view(-1,VOCAB_SIZE), targets.view(-1))\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["   # Training Function"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:30.277398Z","iopub.status.busy":"2022-01-11T16:39:30.274794Z","iopub.status.idle":"2022-01-11T16:39:30.300094Z","shell.execute_reply":"2022-01-11T16:39:30.299364Z","shell.execute_reply.started":"2022-01-11T16:39:30.277364Z"},"trusted":true},"outputs":[],"source":["def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n","    # train 모드로 변경\n","    model.train()\n","\n","    # for the Mixed Precision\n","    # Pytorch 예제 : https://pytorch.org/docs/stable/notes/amp_examples.html#amp-examples\n","    if(FP16):\n","        scaler = amp.GradScaler()\n","\n","    dataset_size = 0\n","    running_loss = 0\n","    running_accuracy = 0\n","    accuracy = 0\n","\n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","\n","    for step, (src, trg_input, trg_output) in bar:\n","        src = src.to(device)\n","        trg_input = trg_input.to(device)\n","        trg_output = trg_output.to(device)\n","\n","        batch_size = src.shape[0]\n","\n","        if(FP16):\n","            with amp.autocast(enabled=True):\n","                logits, output = model(enc_src=src, dec_src=trg_input)\n","                loss = criterion(logits, trg_output)\n","\n","                # loss를 Scale\n","                # Scaled Grdients를 계산(call)하기 위해 scaled loss를 backward()\n","                scaler.scale(loss).backward()\n","                # scaler.step() first unscales the gradients of the optimizer's assigned params.\n","                # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n","                # otherwise, optimizer.step() is skipped.\n","                scaler.step(optimizer)\n","\n","                # Updates the scale for next iteration.\n","                scaler.update()\n","\n","        else:\n","            logits, output = model(enc_src=src, dec_src=trg_input)\n","            loss = criterion(logits, trg_output)\n","\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n","            optimizer.step()\n","\n","        # logits (bs, seq_len, VOCAB_SIZE)\n","        # trg_output (bs, seq_len)\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # change learning rate by Scheduler\n","        if scheduler is not None:\n","            scheduler.step()\n","\n","        # loss.item()은 loss를 Python Float으로 반환\n","        # loss.item()은 batch data의 average loss이므로, sum of loss를 구하기 위해 batch_size를 곱해준다\n","        running_loss += loss.item() * batch_size\n","        running_accuracy = np.mean(\n","            output.view(-1).detach().cpu().numpy() == trg_output.view(-1).detach().cpu().numpy())\n","\n","        accuracy += running_accuracy\n","\n","        dataset_size += batch_size\n","        epoch_loss = running_loss / dataset_size\n","\n","        bar.set_postfix(\n","            Epoch=epoch, Train_Loss=epoch_loss, LR=optimizer.param_groups[0][\"lr\"], accuracy=accuracy / np.float(\n","                step+1)\n","        )\n","\n","        # break\n","\n","    accuracy /= len(dataloader)\n","    # Garbage Collector\n","    gc.collect()\n","\n","    return epoch_loss, accuracy\n"]},{"cell_type":"markdown","metadata":{},"source":["   # Validation Function"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:30.307973Z","iopub.status.busy":"2022-01-11T16:39:30.306082Z","iopub.status.idle":"2022-01-11T16:39:30.320862Z","shell.execute_reply":"2022-01-11T16:39:30.320099Z","shell.execute_reply.started":"2022-01-11T16:39:30.307941Z"},"trusted":true},"outputs":[],"source":["@torch.no_grad()\n","def valid_one_epoch(model, dataloader, device, epoch):\n","    model.eval()\n","\n","    dataset_size = 0\n","    running_loss = 0\n","    accuracy = 0\n","\n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","\n","    for step, (src, trg_input, trg_output) in bar:\n","        src = src.to(device)\n","        trg_input = trg_input.to(device)\n","        trg_output = trg_output.to(device)\n","\n","        batch_size = src.shape[0]\n","\n","        logits, output = model(enc_src = src, dec_src = trg_input)\n","        loss = criterion(logits, trg_output)\n","\n","        running_loss += loss.item() * batch_size\n","        dataset_size += batch_size\n","\n","        # 실시간으로 정보를 표시하기 위한 epoch loss\n","        val_loss = running_loss / dataset_size\n","        running_accuracy = np.mean(output.view(-1).detach().cpu().numpy() == trg_output.view(-1).detach().cpu().numpy())\n","        \n","        accuracy += running_accuracy\n","\n","        bar.set_postfix(\n","            Epoch=epoch, Valid_Loss=val_loss, LR=optimizer.param_groups[0][\"lr\"], accuracy = accuracy / np.float(step + 1)\n","        )\n","\n","        # break\n","\n","    accuracy /= len(dataloader)\n","\n","    gc.collect()\n","\n","    return val_loss, accuracy\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:30.326237Z","iopub.status.busy":"2022-01-11T16:39:30.32462Z","iopub.status.idle":"2022-01-11T16:39:30.343679Z","shell.execute_reply":"2022-01-11T16:39:30.342968Z","shell.execute_reply.started":"2022-01-11T16:39:30.326206Z"},"trusted":true},"outputs":[],"source":["def run_training(\n","    model,\n","    optimizer,\n","    scheduler,\n","    device,\n","    num_epochs,\n","    metric_prefix=\"\",\n","    file_prefix=\"\",\n","    early_stopping=True,\n","    early_stopping_step=10,\n","):\n","    # To automatically log graidents\n","    wandb.watch(model, log_freq=100)\n","\n","    if torch.cuda.is_available():\n","        print(\"[INFO] Using GPU:{}\\n\".format(torch.cuda.get_device_name()))\n","\n","    start = time.time()\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_loss = np.inf\n","    history = defaultdict(list)\n","    early_stop_counter = 0\n","\n","    # num_epochs만큼, train과 val을 실행한다\n","    for epoch in range(1, num_epochs + 1):\n","        gc.collect()\n","\n","        train_epoch_loss, train_accuracy = train_one_epoch(\n","            model,\n","            optimizer,\n","            scheduler,\n","            dataloader= train_dataloader,\n","            device=device,\n","            epoch=epoch,\n","        )\n","\n","        val_loss, val_accuracy = valid_one_epoch(\n","            model, valid_dataloader, device=device, epoch=epoch\n","        )\n","\n","        history[f\"{metric_prefix}Train Loss\"].append(train_epoch_loss)\n","        history[f\"{metric_prefix}Train Accuracy\"].append(train_accuracy)\n","        history[f\"{metric_prefix}Valid Loss\"].append(val_loss)\n","        history[f\"{metric_prefix}Valid Accuracy\"].append(val_accuracy)\n","\n","\n","        # Log the metrics\n","        wandb.log(\n","            {\n","                f\"{metric_prefix}Train Loss\": train_epoch_loss,\n","                f\"{metric_prefix}Valid Loss\": val_loss,\n","                f\"{metric_prefix}Train Accuracy\" : train_accuracy,\n","                f\"{metric_prefix}Valid Accuracy\" : val_accuracy,\n","            }\n","        )\n","\n","        print(f\"Valid Loss : {val_loss}\")\n","\n","        # deep copy the model\n","        if val_loss <= best_loss:\n","            early_stop_counter = 0\n","\n","            print(\n","                f\"Validation Loss improved( {best_loss} ---> {val_loss}  )\"\n","            )\n","\n","            # Update Best Loss\n","            best_loss = val_loss\n","            \n","            # Update Best Model Weight\n","            # run.summary['Best RMSE'] = best_loss\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","\n","            PATH = \"{}epoch{:.0f}_Loss{:.4f}.bin\".format(file_prefix, epoch, best_loss)\n","            torch.save(model.state_dict(), PATH)\n","            torch.save(model.state_dict(), f\"{file_prefix}best_{epoch}epoch.bin\")\n","            # Save a model file from the current directory\n","            wandb.save(PATH)\n","\n","            print(f\"Model Saved\")\n","\n","        elif early_stopping:\n","            early_stop_counter += 1\n","            if early_stop_counter > early_stopping_step:\n","                break\n","        \n","        # break\n","\n","\n","    end = time.time()\n","    time_elapsed = end - start\n","    print(\n","        \"Training complete in {:.0f}h {:.0f}m {:.0f}s\".format(\n","            time_elapsed // 3600,\n","            (time_elapsed % 3600) // 60,\n","            (time_elapsed % 3600) % 60,\n","        )\n","    )\n","    print(\"Best Loss: {:.4f}\".format(best_loss))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","\n","    return model, history\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:30.348437Z","iopub.status.busy":"2022-01-11T16:39:30.346581Z","iopub.status.idle":"2022-01-11T16:39:30.354609Z","shell.execute_reply":"2022-01-11T16:39:30.353899Z","shell.execute_reply.started":"2022-01-11T16:39:30.348407Z"},"trusted":true},"outputs":[],"source":["# wandb.restore('epoch2_Loss7.8590.bin',\n","#               run_path='jiwon7258/Transformer_enko/12t3zwp8',\n","#               root='./')\n","# model.load_state_dict(torch.load('epoch2_Loss7.8590.bin'))\n"]},{"cell_type":"markdown","metadata":{},"source":[" # Run training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T16:39:30.356754Z","iopub.status.busy":"2022-01-11T16:39:30.356104Z","iopub.status.idle":"2022-01-11T17:22:43.719728Z","shell.execute_reply":"2022-01-11T17:22:43.719075Z","shell.execute_reply.started":"2022-01-11T16:39:30.356699Z"},"trusted":true},"outputs":[],"source":["run_training(\n","    model = model,\n","    optimizer = optimizer,\n","    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=100, eta_min=1e-5),\n","    device = device,\n","    num_epochs = 2000,\n","    metric_prefix=\"\",\n","    file_prefix=\"\",\n","    early_stopping=True,\n","    early_stopping_step=10,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T17:22:43.720897Z","iopub.status.busy":"2022-01-11T17:22:43.720676Z","iopub.status.idle":"2022-01-11T17:22:43.829005Z","shell.execute_reply":"2022-01-11T17:22:43.827999Z","shell.execute_reply.started":"2022-01-11T17:22:43.720868Z"},"trusted":true},"outputs":[],"source":["torch.save(model.state_dict(), 'final.bin')\n","wandb.save('final.bin')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-11T17:22:43.830642Z","iopub.status.busy":"2022-01-11T17:22:43.830209Z","iopub.status.idle":"2022-01-11T17:22:49.267901Z","shell.execute_reply":"2022-01-11T17:22:49.267168Z","shell.execute_reply.started":"2022-01-11T17:22:43.830604Z"},"trusted":true},"outputs":[],"source":["wandb.finish()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
